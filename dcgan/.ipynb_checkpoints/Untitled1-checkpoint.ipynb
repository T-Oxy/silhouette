{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "root_dir = \"/Users/user/Desktop/silhouette/\"\n",
    "# input_img_dir = \"icon_resize\"\n",
    "input_img_dir = \"output\"\n",
    "# save_dir = \"icon_dcgan_v0/\"\n",
    "save_dir = \"icon_dcgan_v1/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # Training Discriminator\n",
    "            \n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # Training Generator\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.547255, acc.: 34.38%] [G loss: 0.620884]\n",
      "Generating interpolations...\n",
      "1 [D loss: 0.886340, acc.: 53.12%] [G loss: 0.892499]\n",
      "2 [D loss: 0.561192, acc.: 65.62%] [G loss: 0.837620]\n",
      "3 [D loss: 0.235472, acc.: 96.88%] [G loss: 0.704067]\n",
      "4 [D loss: 0.115233, acc.: 100.00%] [G loss: 0.606500]\n",
      "5 [D loss: 0.066719, acc.: 100.00%] [G loss: 0.352956]\n",
      "6 [D loss: 0.084316, acc.: 100.00%] [G loss: 0.162913]\n",
      "7 [D loss: 0.078829, acc.: 100.00%] [G loss: 0.075485]\n",
      "8 [D loss: 0.052350, acc.: 100.00%] [G loss: 0.045654]\n",
      "9 [D loss: 0.042088, acc.: 100.00%] [G loss: 0.016540]\n",
      "10 [D loss: 0.074308, acc.: 100.00%] [G loss: 0.025021]\n",
      "11 [D loss: 0.040629, acc.: 100.00%] [G loss: 0.015237]\n",
      "12 [D loss: 0.042259, acc.: 100.00%] [G loss: 0.007818]\n",
      "13 [D loss: 0.044078, acc.: 100.00%] [G loss: 0.018040]\n",
      "14 [D loss: 0.027641, acc.: 100.00%] [G loss: 0.018902]\n",
      "15 [D loss: 0.041315, acc.: 100.00%] [G loss: 0.026485]\n",
      "16 [D loss: 0.084990, acc.: 100.00%] [G loss: 0.050836]\n",
      "17 [D loss: 0.095274, acc.: 100.00%] [G loss: 0.087828]\n",
      "18 [D loss: 0.253682, acc.: 87.50%] [G loss: 0.484220]\n",
      "19 [D loss: 0.800812, acc.: 62.50%] [G loss: 1.794010]\n",
      "20 [D loss: 2.958257, acc.: 3.12%] [G loss: 1.260299]\n",
      "21 [D loss: 1.022318, acc.: 46.88%] [G loss: 4.191406]\n",
      "22 [D loss: 2.815843, acc.: 15.62%] [G loss: 2.398383]\n",
      "23 [D loss: 1.621176, acc.: 31.25%] [G loss: 1.989632]\n",
      "24 [D loss: 0.748078, acc.: 56.25%] [G loss: 3.104189]\n",
      "25 [D loss: 1.287069, acc.: 21.88%] [G loss: 1.128765]\n",
      "26 [D loss: 0.955482, acc.: 43.75%] [G loss: 2.905762]\n",
      "27 [D loss: 1.277451, acc.: 21.88%] [G loss: 1.580204]\n",
      "28 [D loss: 0.764917, acc.: 62.50%] [G loss: 2.132677]\n",
      "29 [D loss: 1.338283, acc.: 31.25%] [G loss: 4.132216]\n",
      "30 [D loss: 1.050511, acc.: 50.00%] [G loss: 1.180329]\n",
      "31 [D loss: 1.044936, acc.: 46.88%] [G loss: 2.462827]\n",
      "32 [D loss: 0.876410, acc.: 40.62%] [G loss: 2.158678]\n",
      "33 [D loss: 0.316777, acc.: 81.25%] [G loss: 1.548536]\n",
      "34 [D loss: 0.485876, acc.: 81.25%] [G loss: 1.879810]\n",
      "35 [D loss: 0.628399, acc.: 75.00%] [G loss: 2.254125]\n",
      "36 [D loss: 0.811992, acc.: 59.38%] [G loss: 2.171177]\n",
      "37 [D loss: 0.480452, acc.: 90.62%] [G loss: 0.999054]\n",
      "38 [D loss: 0.426008, acc.: 87.50%] [G loss: 1.533031]\n",
      "39 [D loss: 0.461997, acc.: 81.25%] [G loss: 2.006314]\n",
      "40 [D loss: 0.122581, acc.: 96.88%] [G loss: 1.894268]\n",
      "41 [D loss: 0.100158, acc.: 96.88%] [G loss: 1.228321]\n",
      "42 [D loss: 0.139613, acc.: 96.88%] [G loss: 2.219828]\n",
      "43 [D loss: 0.645886, acc.: 71.88%] [G loss: 0.645394]\n",
      "44 [D loss: 0.199707, acc.: 87.50%] [G loss: 0.978654]\n",
      "45 [D loss: 0.070211, acc.: 96.88%] [G loss: 0.970718]\n",
      "46 [D loss: 0.125075, acc.: 96.88%] [G loss: 1.038638]\n",
      "47 [D loss: 0.054849, acc.: 100.00%] [G loss: 0.721183]\n",
      "48 [D loss: 0.033826, acc.: 100.00%] [G loss: 0.931865]\n",
      "49 [D loss: 0.302886, acc.: 90.62%] [G loss: 0.512847]\n",
      "50 [D loss: 0.040645, acc.: 100.00%] [G loss: 0.988023]\n",
      "51 [D loss: 0.025984, acc.: 100.00%] [G loss: 0.833984]\n",
      "52 [D loss: 0.036675, acc.: 100.00%] [G loss: 0.534794]\n",
      "53 [D loss: 0.077480, acc.: 100.00%] [G loss: 0.183231]\n",
      "54 [D loss: 0.043974, acc.: 100.00%] [G loss: 0.358240]\n",
      "55 [D loss: 0.052133, acc.: 100.00%] [G loss: 0.669198]\n",
      "56 [D loss: 0.032196, acc.: 100.00%] [G loss: 0.470348]\n",
      "57 [D loss: 0.024124, acc.: 100.00%] [G loss: 0.508564]\n",
      "58 [D loss: 0.016757, acc.: 100.00%] [G loss: 0.604438]\n",
      "59 [D loss: 0.007624, acc.: 100.00%] [G loss: 0.556444]\n",
      "60 [D loss: 0.088202, acc.: 96.88%] [G loss: 0.063446]\n",
      "61 [D loss: 0.042732, acc.: 100.00%] [G loss: 0.225800]\n",
      "62 [D loss: 0.022590, acc.: 100.00%] [G loss: 0.257839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 [D loss: 0.046056, acc.: 100.00%] [G loss: 0.205019]\n",
      "64 [D loss: 0.025119, acc.: 100.00%] [G loss: 0.241976]\n",
      "65 [D loss: 0.012164, acc.: 100.00%] [G loss: 0.279491]\n",
      "66 [D loss: 0.007267, acc.: 100.00%] [G loss: 0.302167]\n",
      "67 [D loss: 0.010269, acc.: 100.00%] [G loss: 0.265595]\n",
      "68 [D loss: 0.023089, acc.: 100.00%] [G loss: 0.185193]\n",
      "69 [D loss: 0.052214, acc.: 100.00%] [G loss: 0.180233]\n",
      "70 [D loss: 0.027786, acc.: 100.00%] [G loss: 0.210657]\n",
      "71 [D loss: 0.012990, acc.: 100.00%] [G loss: 0.309266]\n",
      "72 [D loss: 0.138249, acc.: 96.88%] [G loss: 0.072220]\n",
      "73 [D loss: 0.086116, acc.: 100.00%] [G loss: 0.375172]\n",
      "74 [D loss: 0.001488, acc.: 100.00%] [G loss: 0.764174]\n",
      "75 [D loss: 0.002450, acc.: 100.00%] [G loss: 0.818962]\n",
      "76 [D loss: 0.054446, acc.: 100.00%] [G loss: 0.133827]\n",
      "77 [D loss: 0.005593, acc.: 100.00%] [G loss: 0.068473]\n",
      "78 [D loss: 0.017469, acc.: 100.00%] [G loss: 0.070027]\n",
      "79 [D loss: 0.009739, acc.: 100.00%] [G loss: 0.097191]\n",
      "80 [D loss: 0.006882, acc.: 100.00%] [G loss: 0.088411]\n",
      "81 [D loss: 0.013129, acc.: 100.00%] [G loss: 0.130318]\n",
      "82 [D loss: 0.018007, acc.: 100.00%] [G loss: 0.125470]\n",
      "83 [D loss: 0.004133, acc.: 100.00%] [G loss: 0.105421]\n",
      "84 [D loss: 0.008109, acc.: 100.00%] [G loss: 0.126246]\n",
      "85 [D loss: 0.007561, acc.: 100.00%] [G loss: 0.126945]\n",
      "86 [D loss: 0.006850, acc.: 100.00%] [G loss: 0.136138]\n",
      "87 [D loss: 0.004172, acc.: 100.00%] [G loss: 0.148657]\n",
      "88 [D loss: 0.003294, acc.: 100.00%] [G loss: 0.151803]\n",
      "89 [D loss: 0.003202, acc.: 100.00%] [G loss: 0.100655]\n",
      "90 [D loss: 0.002461, acc.: 100.00%] [G loss: 0.120252]\n",
      "91 [D loss: 0.002901, acc.: 100.00%] [G loss: 0.102277]\n",
      "92 [D loss: 0.010796, acc.: 100.00%] [G loss: 0.083224]\n",
      "93 [D loss: 0.008877, acc.: 100.00%] [G loss: 0.089217]\n",
      "94 [D loss: 0.002171, acc.: 100.00%] [G loss: 0.080872]\n",
      "95 [D loss: 0.004812, acc.: 100.00%] [G loss: 0.103398]\n",
      "96 [D loss: 0.004880, acc.: 100.00%] [G loss: 0.146567]\n",
      "97 [D loss: 0.005131, acc.: 100.00%] [G loss: 0.085813]\n",
      "98 [D loss: 0.003064, acc.: 100.00%] [G loss: 0.118657]\n",
      "99 [D loss: 0.001647, acc.: 100.00%] [G loss: 0.087587]\n",
      "100 [D loss: 0.008393, acc.: 100.00%] [G loss: 0.079903]\n",
      "Generating interpolations...\n",
      "101 [D loss: 0.015667, acc.: 100.00%] [G loss: 0.104573]\n",
      "102 [D loss: 0.002814, acc.: 100.00%] [G loss: 0.099490]\n",
      "103 [D loss: 0.018044, acc.: 100.00%] [G loss: 0.083791]\n",
      "104 [D loss: 0.003498, acc.: 100.00%] [G loss: 0.076971]\n",
      "105 [D loss: 0.005407, acc.: 100.00%] [G loss: 0.102964]\n",
      "106 [D loss: 0.010547, acc.: 100.00%] [G loss: 0.137510]\n",
      "107 [D loss: 0.009865, acc.: 100.00%] [G loss: 0.137578]\n",
      "108 [D loss: 0.002556, acc.: 100.00%] [G loss: 0.116611]\n",
      "109 [D loss: 0.003751, acc.: 100.00%] [G loss: 0.074888]\n",
      "110 [D loss: 0.002798, acc.: 100.00%] [G loss: 0.042569]\n",
      "111 [D loss: 0.016380, acc.: 100.00%] [G loss: 0.061682]\n",
      "112 [D loss: 0.016401, acc.: 100.00%] [G loss: 0.065479]\n",
      "113 [D loss: 0.003617, acc.: 100.00%] [G loss: 0.045576]\n",
      "114 [D loss: 0.002958, acc.: 100.00%] [G loss: 0.035552]\n",
      "115 [D loss: 0.007297, acc.: 100.00%] [G loss: 0.054379]\n",
      "116 [D loss: 0.002664, acc.: 100.00%] [G loss: 0.047351]\n",
      "117 [D loss: 0.004682, acc.: 100.00%] [G loss: 0.051817]\n",
      "118 [D loss: 0.003759, acc.: 100.00%] [G loss: 0.087285]\n",
      "119 [D loss: 0.002634, acc.: 100.00%] [G loss: 0.093465]\n",
      "120 [D loss: 0.002990, acc.: 100.00%] [G loss: 0.086890]\n",
      "121 [D loss: 0.001544, acc.: 100.00%] [G loss: 0.095113]\n",
      "122 [D loss: 0.000527, acc.: 100.00%] [G loss: 0.052987]\n",
      "123 [D loss: 0.003088, acc.: 100.00%] [G loss: 0.063550]\n",
      "124 [D loss: 0.001051, acc.: 100.00%] [G loss: 0.037028]\n",
      "125 [D loss: 0.001758, acc.: 100.00%] [G loss: 0.038263]\n",
      "126 [D loss: 0.001238, acc.: 100.00%] [G loss: 0.035023]\n",
      "127 [D loss: 0.001232, acc.: 100.00%] [G loss: 0.039982]\n",
      "128 [D loss: 0.001981, acc.: 100.00%] [G loss: 0.043375]\n",
      "129 [D loss: 0.004333, acc.: 100.00%] [G loss: 0.079729]\n",
      "130 [D loss: 0.001412, acc.: 100.00%] [G loss: 0.069272]\n",
      "131 [D loss: 0.010280, acc.: 100.00%] [G loss: 0.053129]\n",
      "132 [D loss: 0.001139, acc.: 100.00%] [G loss: 0.061132]\n",
      "133 [D loss: 0.001528, acc.: 100.00%] [G loss: 0.037044]\n",
      "134 [D loss: 0.008144, acc.: 100.00%] [G loss: 0.044336]\n",
      "135 [D loss: 0.002974, acc.: 100.00%] [G loss: 0.074785]\n",
      "136 [D loss: 0.001633, acc.: 100.00%] [G loss: 0.043259]\n",
      "137 [D loss: 0.002113, acc.: 100.00%] [G loss: 0.063901]\n",
      "138 [D loss: 0.005351, acc.: 100.00%] [G loss: 0.080382]\n",
      "139 [D loss: 0.002466, acc.: 100.00%] [G loss: 0.073194]\n",
      "140 [D loss: 0.002113, acc.: 100.00%] [G loss: 0.062081]\n",
      "141 [D loss: 0.002373, acc.: 100.00%] [G loss: 0.065541]\n",
      "142 [D loss: 0.001178, acc.: 100.00%] [G loss: 0.045681]\n",
      "143 [D loss: 0.001156, acc.: 100.00%] [G loss: 0.061442]\n",
      "144 [D loss: 0.049194, acc.: 96.88%] [G loss: 0.025392]\n",
      "145 [D loss: 0.009902, acc.: 100.00%] [G loss: 0.023197]\n",
      "146 [D loss: 0.006981, acc.: 100.00%] [G loss: 0.019609]\n",
      "147 [D loss: 0.004260, acc.: 100.00%] [G loss: 0.048491]\n",
      "148 [D loss: 0.002350, acc.: 100.00%] [G loss: 0.067398]\n",
      "149 [D loss: 0.003927, acc.: 100.00%] [G loss: 0.038716]\n",
      "150 [D loss: 0.001259, acc.: 100.00%] [G loss: 0.063459]\n",
      "151 [D loss: 0.000434, acc.: 100.00%] [G loss: 0.053987]\n",
      "152 [D loss: 0.000750, acc.: 100.00%] [G loss: 0.097777]\n",
      "153 [D loss: 0.001215, acc.: 100.00%] [G loss: 0.103786]\n",
      "154 [D loss: 0.092107, acc.: 100.00%] [G loss: 0.008051]\n",
      "155 [D loss: 0.016125, acc.: 100.00%] [G loss: 0.006592]\n",
      "156 [D loss: 0.002815, acc.: 100.00%] [G loss: 0.010894]\n",
      "157 [D loss: 0.001917, acc.: 100.00%] [G loss: 0.024983]\n",
      "158 [D loss: 0.000585, acc.: 100.00%] [G loss: 0.017501]\n",
      "159 [D loss: 0.000780, acc.: 100.00%] [G loss: 0.013932]\n",
      "160 [D loss: 0.000862, acc.: 100.00%] [G loss: 0.024622]\n",
      "161 [D loss: 0.001109, acc.: 100.00%] [G loss: 0.010233]\n",
      "162 [D loss: 0.000194, acc.: 100.00%] [G loss: 0.008495]\n",
      "163 [D loss: 0.001017, acc.: 100.00%] [G loss: 0.036614]\n",
      "164 [D loss: 0.000442, acc.: 100.00%] [G loss: 0.021201]\n",
      "165 [D loss: 0.000720, acc.: 100.00%] [G loss: 0.044928]\n",
      "166 [D loss: 0.000285, acc.: 100.00%] [G loss: 0.038981]\n",
      "167 [D loss: 0.000234, acc.: 100.00%] [G loss: 0.014861]\n",
      "168 [D loss: 0.000336, acc.: 100.00%] [G loss: 0.021554]\n",
      "169 [D loss: 0.000185, acc.: 100.00%] [G loss: 0.018465]\n",
      "170 [D loss: 0.000587, acc.: 100.00%] [G loss: 0.016875]\n",
      "171 [D loss: 0.000632, acc.: 100.00%] [G loss: 0.014750]\n",
      "172 [D loss: 0.000480, acc.: 100.00%] [G loss: 0.014614]\n",
      "173 [D loss: 0.000355, acc.: 100.00%] [G loss: 0.019902]\n",
      "174 [D loss: 0.000260, acc.: 100.00%] [G loss: 0.023168]\n",
      "175 [D loss: 0.000322, acc.: 100.00%] [G loss: 0.017916]\n",
      "176 [D loss: 0.001389, acc.: 100.00%] [G loss: 0.036374]\n",
      "177 [D loss: 0.000325, acc.: 100.00%] [G loss: 0.021544]\n",
      "178 [D loss: 0.000529, acc.: 100.00%] [G loss: 0.011453]\n",
      "179 [D loss: 0.000433, acc.: 100.00%] [G loss: 0.014769]\n",
      "180 [D loss: 0.000348, acc.: 100.00%] [G loss: 0.009815]\n",
      "181 [D loss: 0.001278, acc.: 100.00%] [G loss: 0.014285]\n",
      "182 [D loss: 0.000734, acc.: 100.00%] [G loss: 0.028844]\n",
      "183 [D loss: 0.000709, acc.: 100.00%] [G loss: 0.029887]\n",
      "184 [D loss: 0.004144, acc.: 100.00%] [G loss: 0.066028]\n",
      "185 [D loss: 0.000498, acc.: 100.00%] [G loss: 0.063115]\n",
      "186 [D loss: 0.000886, acc.: 100.00%] [G loss: 0.039470]\n",
      "187 [D loss: 0.000354, acc.: 100.00%] [G loss: 0.027791]\n",
      "188 [D loss: 0.000414, acc.: 100.00%] [G loss: 0.022618]\n",
      "189 [D loss: 0.000430, acc.: 100.00%] [G loss: 0.022132]\n",
      "190 [D loss: 0.000626, acc.: 100.00%] [G loss: 0.039274]\n",
      "191 [D loss: 0.000462, acc.: 100.00%] [G loss: 0.033781]\n",
      "192 [D loss: 0.001563, acc.: 100.00%] [G loss: 0.033912]\n",
      "193 [D loss: 0.000464, acc.: 100.00%] [G loss: 0.021504]\n",
      "194 [D loss: 0.000646, acc.: 100.00%] [G loss: 0.022951]\n",
      "195 [D loss: 0.000453, acc.: 100.00%] [G loss: 0.022762]\n",
      "196 [D loss: 0.001873, acc.: 100.00%] [G loss: 0.034540]\n",
      "197 [D loss: 0.000404, acc.: 100.00%] [G loss: 0.016114]\n",
      "198 [D loss: 0.000541, acc.: 100.00%] [G loss: 0.017833]\n",
      "199 [D loss: 0.000213, acc.: 100.00%] [G loss: 0.012339]\n",
      "200 [D loss: 0.000937, acc.: 100.00%] [G loss: 0.010021]\n",
      "Generating interpolations...\n",
      "201 [D loss: 0.000410, acc.: 100.00%] [G loss: 0.012141]\n",
      "202 [D loss: 0.000148, acc.: 100.00%] [G loss: 0.021800]\n",
      "203 [D loss: 0.000928, acc.: 100.00%] [G loss: 0.041051]\n",
      "204 [D loss: 0.000433, acc.: 100.00%] [G loss: 0.021912]\n",
      "205 [D loss: 0.000314, acc.: 100.00%] [G loss: 0.016919]\n",
      "206 [D loss: 0.000346, acc.: 100.00%] [G loss: 0.018475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 [D loss: 0.026802, acc.: 100.00%] [G loss: 0.009172]\n",
      "208 [D loss: 0.005617, acc.: 100.00%] [G loss: 0.003131]\n",
      "209 [D loss: 0.001750, acc.: 100.00%] [G loss: 0.004185]\n",
      "210 [D loss: 0.002820, acc.: 100.00%] [G loss: 0.003737]\n",
      "211 [D loss: 0.000638, acc.: 100.00%] [G loss: 0.005845]\n",
      "212 [D loss: 0.000962, acc.: 100.00%] [G loss: 0.007410]\n",
      "213 [D loss: 0.000939, acc.: 100.00%] [G loss: 0.005953]\n",
      "214 [D loss: 0.000668, acc.: 100.00%] [G loss: 0.002680]\n",
      "215 [D loss: 0.000422, acc.: 100.00%] [G loss: 0.009115]\n",
      "216 [D loss: 0.000491, acc.: 100.00%] [G loss: 0.005035]\n",
      "217 [D loss: 0.000271, acc.: 100.00%] [G loss: 0.003603]\n",
      "218 [D loss: 0.000435, acc.: 100.00%] [G loss: 0.004430]\n",
      "219 [D loss: 0.000750, acc.: 100.00%] [G loss: 0.007291]\n",
      "220 [D loss: 0.000220, acc.: 100.00%] [G loss: 0.013358]\n",
      "221 [D loss: 0.000153, acc.: 100.00%] [G loss: 0.010541]\n",
      "222 [D loss: 0.000477, acc.: 100.00%] [G loss: 0.006289]\n",
      "223 [D loss: 0.000214, acc.: 100.00%] [G loss: 0.003724]\n",
      "224 [D loss: 0.000268, acc.: 100.00%] [G loss: 0.010031]\n",
      "225 [D loss: 0.000198, acc.: 100.00%] [G loss: 0.013371]\n",
      "226 [D loss: 0.000415, acc.: 100.00%] [G loss: 0.009826]\n",
      "227 [D loss: 0.000133, acc.: 100.00%] [G loss: 0.006320]\n",
      "228 [D loss: 0.000314, acc.: 100.00%] [G loss: 0.010080]\n",
      "229 [D loss: 0.000454, acc.: 100.00%] [G loss: 0.006401]\n",
      "230 [D loss: 0.000199, acc.: 100.00%] [G loss: 0.009566]\n",
      "231 [D loss: 0.000222, acc.: 100.00%] [G loss: 0.004707]\n",
      "232 [D loss: 0.000169, acc.: 100.00%] [G loss: 0.012232]\n",
      "233 [D loss: 0.000157, acc.: 100.00%] [G loss: 0.008597]\n",
      "234 [D loss: 0.000146, acc.: 100.00%] [G loss: 0.006293]\n",
      "235 [D loss: 0.000281, acc.: 100.00%] [G loss: 0.011485]\n",
      "236 [D loss: 0.000272, acc.: 100.00%] [G loss: 0.029252]\n",
      "237 [D loss: 0.002016, acc.: 100.00%] [G loss: 0.055964]\n",
      "238 [D loss: 0.000184, acc.: 100.00%] [G loss: 0.014159]\n",
      "239 [D loss: 0.000220, acc.: 100.00%] [G loss: 0.018362]\n",
      "240 [D loss: 0.000449, acc.: 100.00%] [G loss: 0.025055]\n",
      "241 [D loss: 0.000286, acc.: 100.00%] [G loss: 0.015403]\n",
      "242 [D loss: 0.000455, acc.: 100.00%] [G loss: 0.010009]\n",
      "243 [D loss: 0.000180, acc.: 100.00%] [G loss: 0.011877]\n",
      "244 [D loss: 0.000195, acc.: 100.00%] [G loss: 0.013479]\n",
      "245 [D loss: 0.001163, acc.: 100.00%] [G loss: 0.023807]\n",
      "246 [D loss: 0.000469, acc.: 100.00%] [G loss: 0.018405]\n",
      "247 [D loss: 0.000207, acc.: 100.00%] [G loss: 0.028697]\n",
      "248 [D loss: 0.000274, acc.: 100.00%] [G loss: 0.019352]\n",
      "249 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.023336]\n",
      "250 [D loss: 0.000353, acc.: 100.00%] [G loss: 0.014273]\n",
      "251 [D loss: 0.000223, acc.: 100.00%] [G loss: 0.028251]\n",
      "252 [D loss: 0.000194, acc.: 100.00%] [G loss: 0.014135]\n",
      "253 [D loss: 0.000384, acc.: 100.00%] [G loss: 0.013677]\n",
      "254 [D loss: 0.000195, acc.: 100.00%] [G loss: 0.013275]\n",
      "255 [D loss: 0.000097, acc.: 100.00%] [G loss: 0.017040]\n",
      "256 [D loss: 0.000245, acc.: 100.00%] [G loss: 0.015209]\n",
      "257 [D loss: 0.000162, acc.: 100.00%] [G loss: 0.013742]\n",
      "258 [D loss: 0.000166, acc.: 100.00%] [G loss: 0.011932]\n",
      "259 [D loss: 0.000281, acc.: 100.00%] [G loss: 0.019937]\n",
      "260 [D loss: 0.000336, acc.: 100.00%] [G loss: 0.024743]\n",
      "261 [D loss: 0.000209, acc.: 100.00%] [G loss: 0.017383]\n",
      "262 [D loss: 0.000596, acc.: 100.00%] [G loss: 0.021643]\n",
      "263 [D loss: 0.000228, acc.: 100.00%] [G loss: 0.033874]\n",
      "264 [D loss: 0.000143, acc.: 100.00%] [G loss: 0.014804]\n",
      "265 [D loss: 0.000564, acc.: 100.00%] [G loss: 0.038678]\n",
      "266 [D loss: 0.000293, acc.: 100.00%] [G loss: 0.037892]\n",
      "267 [D loss: 0.001236, acc.: 100.00%] [G loss: 0.058090]\n",
      "268 [D loss: 0.001329, acc.: 100.00%] [G loss: 0.068584]\n",
      "269 [D loss: 0.000424, acc.: 100.00%] [G loss: 0.039071]\n",
      "270 [D loss: 0.000274, acc.: 100.00%] [G loss: 0.027831]\n",
      "271 [D loss: 0.000191, acc.: 100.00%] [G loss: 0.011292]\n",
      "272 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.016395]\n",
      "273 [D loss: 0.000801, acc.: 100.00%] [G loss: 0.020599]\n",
      "274 [D loss: 0.000152, acc.: 100.00%] [G loss: 0.017759]\n",
      "275 [D loss: 0.000335, acc.: 100.00%] [G loss: 0.010849]\n",
      "276 [D loss: 0.000241, acc.: 100.00%] [G loss: 0.006782]\n",
      "277 [D loss: 0.000205, acc.: 100.00%] [G loss: 0.003113]\n",
      "278 [D loss: 0.000678, acc.: 100.00%] [G loss: 0.015869]\n",
      "279 [D loss: 0.001548, acc.: 100.00%] [G loss: 0.020129]\n",
      "280 [D loss: 0.000225, acc.: 100.00%] [G loss: 0.013039]\n",
      "281 [D loss: 0.000644, acc.: 100.00%] [G loss: 0.021328]\n",
      "282 [D loss: 0.000383, acc.: 100.00%] [G loss: 0.020948]\n",
      "283 [D loss: 0.000141, acc.: 100.00%] [G loss: 0.010065]\n",
      "284 [D loss: 0.000246, acc.: 100.00%] [G loss: 0.005308]\n",
      "285 [D loss: 0.000242, acc.: 100.00%] [G loss: 0.013824]\n",
      "286 [D loss: 0.000165, acc.: 100.00%] [G loss: 0.007281]\n",
      "287 [D loss: 0.000201, acc.: 100.00%] [G loss: 0.007201]\n",
      "288 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.009677]\n",
      "289 [D loss: 0.000170, acc.: 100.00%] [G loss: 0.006952]\n",
      "290 [D loss: 0.000152, acc.: 100.00%] [G loss: 0.011221]\n",
      "291 [D loss: 0.000170, acc.: 100.00%] [G loss: 0.007642]\n",
      "292 [D loss: 0.000142, acc.: 100.00%] [G loss: 0.005865]\n",
      "293 [D loss: 0.000259, acc.: 100.00%] [G loss: 0.008079]\n",
      "294 [D loss: 0.000230, acc.: 100.00%] [G loss: 0.016268]\n",
      "295 [D loss: 0.000202, acc.: 100.00%] [G loss: 0.009667]\n",
      "296 [D loss: 0.000580, acc.: 100.00%] [G loss: 0.005217]\n",
      "297 [D loss: 0.000129, acc.: 100.00%] [G loss: 0.004337]\n",
      "298 [D loss: 0.000251, acc.: 100.00%] [G loss: 0.004984]\n",
      "299 [D loss: 0.001970, acc.: 100.00%] [G loss: 0.022671]\n",
      "300 [D loss: 0.000198, acc.: 100.00%] [G loss: 0.018007]\n",
      "Generating interpolations...\n",
      "301 [D loss: 0.001298, acc.: 100.00%] [G loss: 0.028028]\n",
      "302 [D loss: 0.000115, acc.: 100.00%] [G loss: 0.013977]\n",
      "303 [D loss: 0.000207, acc.: 100.00%] [G loss: 0.009603]\n",
      "304 [D loss: 0.000460, acc.: 100.00%] [G loss: 0.016832]\n",
      "305 [D loss: 0.000136, acc.: 100.00%] [G loss: 0.008315]\n",
      "306 [D loss: 0.000207, acc.: 100.00%] [G loss: 0.006074]\n",
      "307 [D loss: 0.000379, acc.: 100.00%] [G loss: 0.004113]\n",
      "308 [D loss: 0.000208, acc.: 100.00%] [G loss: 0.004966]\n",
      "309 [D loss: 0.000165, acc.: 100.00%] [G loss: 0.005022]\n",
      "310 [D loss: 0.000280, acc.: 100.00%] [G loss: 0.011362]\n",
      "311 [D loss: 0.000130, acc.: 100.00%] [G loss: 0.013448]\n",
      "312 [D loss: 0.001006, acc.: 100.00%] [G loss: 0.030794]\n",
      "313 [D loss: 0.000563, acc.: 100.00%] [G loss: 0.013828]\n",
      "314 [D loss: 0.000480, acc.: 100.00%] [G loss: 0.015982]\n",
      "315 [D loss: 0.000199, acc.: 100.00%] [G loss: 0.011153]\n",
      "316 [D loss: 0.000162, acc.: 100.00%] [G loss: 0.002482]\n",
      "317 [D loss: 0.000361, acc.: 100.00%] [G loss: 0.003268]\n",
      "318 [D loss: 0.000316, acc.: 100.00%] [G loss: 0.003955]\n",
      "319 [D loss: 0.000118, acc.: 100.00%] [G loss: 0.001688]\n",
      "320 [D loss: 0.000174, acc.: 100.00%] [G loss: 0.006414]\n",
      "321 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.005002]\n",
      "322 [D loss: 0.000144, acc.: 100.00%] [G loss: 0.004504]\n",
      "323 [D loss: 0.000217, acc.: 100.00%] [G loss: 0.002512]\n",
      "324 [D loss: 0.000124, acc.: 100.00%] [G loss: 0.002400]\n",
      "325 [D loss: 0.000118, acc.: 100.00%] [G loss: 0.002032]\n",
      "326 [D loss: 0.000264, acc.: 100.00%] [G loss: 0.001793]\n",
      "327 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.003193]\n",
      "328 [D loss: 0.000249, acc.: 100.00%] [G loss: 0.008170]\n",
      "329 [D loss: 0.000881, acc.: 100.00%] [G loss: 0.016072]\n",
      "330 [D loss: 0.000463, acc.: 100.00%] [G loss: 0.022439]\n",
      "331 [D loss: 0.000117, acc.: 100.00%] [G loss: 0.008740]\n",
      "332 [D loss: 0.000487, acc.: 100.00%] [G loss: 0.011611]\n",
      "333 [D loss: 0.000670, acc.: 100.00%] [G loss: 0.017020]\n",
      "334 [D loss: 0.000406, acc.: 100.00%] [G loss: 0.024715]\n",
      "335 [D loss: 0.000141, acc.: 100.00%] [G loss: 0.017340]\n",
      "336 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.022289]\n",
      "337 [D loss: 0.001374, acc.: 100.00%] [G loss: 0.025945]\n",
      "338 [D loss: 0.000453, acc.: 100.00%] [G loss: 0.024472]\n",
      "339 [D loss: 0.000138, acc.: 100.00%] [G loss: 0.009035]\n",
      "340 [D loss: 0.000267, acc.: 100.00%] [G loss: 0.006996]\n",
      "341 [D loss: 0.000118, acc.: 100.00%] [G loss: 0.004899]\n",
      "342 [D loss: 0.000616, acc.: 100.00%] [G loss: 0.012094]\n",
      "343 [D loss: 0.000350, acc.: 100.00%] [G loss: 0.014762]\n",
      "344 [D loss: 0.000094, acc.: 100.00%] [G loss: 0.009090]\n",
      "345 [D loss: 0.000097, acc.: 100.00%] [G loss: 0.007342]\n",
      "346 [D loss: 0.000249, acc.: 100.00%] [G loss: 0.008622]\n",
      "347 [D loss: 0.000126, acc.: 100.00%] [G loss: 0.009872]\n",
      "348 [D loss: 0.000150, acc.: 100.00%] [G loss: 0.005639]\n",
      "349 [D loss: 0.000228, acc.: 100.00%] [G loss: 0.012230]\n",
      "350 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.009854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 [D loss: 0.000216, acc.: 100.00%] [G loss: 0.006565]\n",
      "352 [D loss: 0.000104, acc.: 100.00%] [G loss: 0.004137]\n",
      "353 [D loss: 0.000095, acc.: 100.00%] [G loss: 0.004699]\n",
      "354 [D loss: 0.001022, acc.: 100.00%] [G loss: 0.011752]\n",
      "355 [D loss: 0.000217, acc.: 100.00%] [G loss: 0.007802]\n",
      "356 [D loss: 0.000174, acc.: 100.00%] [G loss: 0.004898]\n",
      "357 [D loss: 0.001263, acc.: 100.00%] [G loss: 0.009804]\n",
      "358 [D loss: 0.000215, acc.: 100.00%] [G loss: 0.014067]\n",
      "359 [D loss: 0.000502, acc.: 100.00%] [G loss: 0.019984]\n",
      "360 [D loss: 0.000185, acc.: 100.00%] [G loss: 0.014519]\n",
      "361 [D loss: 0.000314, acc.: 100.00%] [G loss: 0.005476]\n",
      "362 [D loss: 0.000132, acc.: 100.00%] [G loss: 0.003362]\n",
      "363 [D loss: 0.000186, acc.: 100.00%] [G loss: 0.006051]\n",
      "364 [D loss: 0.000100, acc.: 100.00%] [G loss: 0.007524]\n",
      "365 [D loss: 0.000129, acc.: 100.00%] [G loss: 0.006488]\n",
      "366 [D loss: 0.000118, acc.: 100.00%] [G loss: 0.005016]\n",
      "367 [D loss: 0.000167, acc.: 100.00%] [G loss: 0.004648]\n",
      "368 [D loss: 0.000182, acc.: 100.00%] [G loss: 0.002264]\n",
      "369 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.003108]\n",
      "370 [D loss: 0.000055, acc.: 100.00%] [G loss: 0.002069]\n",
      "371 [D loss: 0.000195, acc.: 100.00%] [G loss: 0.002101]\n",
      "372 [D loss: 0.000090, acc.: 100.00%] [G loss: 0.003444]\n",
      "373 [D loss: 0.000304, acc.: 100.00%] [G loss: 0.009200]\n",
      "374 [D loss: 0.000158, acc.: 100.00%] [G loss: 0.006140]\n",
      "375 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.006924]\n",
      "376 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.005503]\n",
      "377 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.003149]\n",
      "378 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.004693]\n",
      "379 [D loss: 0.000149, acc.: 100.00%] [G loss: 0.004748]\n",
      "380 [D loss: 0.000083, acc.: 100.00%] [G loss: 0.004673]\n",
      "381 [D loss: 0.000103, acc.: 100.00%] [G loss: 0.003541]\n",
      "382 [D loss: 0.000113, acc.: 100.00%] [G loss: 0.006161]\n",
      "383 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.006421]\n",
      "384 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.004819]\n",
      "385 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.003487]\n",
      "386 [D loss: 0.000228, acc.: 100.00%] [G loss: 0.004564]\n",
      "387 [D loss: 0.000124, acc.: 100.00%] [G loss: 0.004330]\n",
      "388 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.005208]\n",
      "389 [D loss: 0.000108, acc.: 100.00%] [G loss: 0.004530]\n",
      "390 [D loss: 0.000091, acc.: 100.00%] [G loss: 0.004132]\n",
      "391 [D loss: 0.000209, acc.: 100.00%] [G loss: 0.008917]\n",
      "392 [D loss: 0.000334, acc.: 100.00%] [G loss: 0.014679]\n",
      "393 [D loss: 0.000189, acc.: 100.00%] [G loss: 0.013694]\n",
      "394 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.010157]\n",
      "395 [D loss: 0.001581, acc.: 100.00%] [G loss: 0.024955]\n",
      "396 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.012017]\n",
      "397 [D loss: 0.000168, acc.: 100.00%] [G loss: 0.003576]\n",
      "398 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.007186]\n",
      "399 [D loss: 0.000084, acc.: 100.00%] [G loss: 0.004200]\n",
      "400 [D loss: 0.002383, acc.: 100.00%] [G loss: 0.011177]\n",
      "Generating interpolations...\n",
      "401 [D loss: 0.000077, acc.: 100.00%] [G loss: 0.003012]\n",
      "402 [D loss: 0.000132, acc.: 100.00%] [G loss: 0.002827]\n",
      "403 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.000865]\n",
      "404 [D loss: 0.000334, acc.: 100.00%] [G loss: 0.004283]\n",
      "405 [D loss: 0.000131, acc.: 100.00%] [G loss: 0.002979]\n",
      "406 [D loss: 0.000235, acc.: 100.00%] [G loss: 0.004142]\n",
      "407 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.004010]\n",
      "408 [D loss: 0.000224, acc.: 100.00%] [G loss: 0.008463]\n",
      "409 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.006337]\n",
      "410 [D loss: 0.000123, acc.: 100.00%] [G loss: 0.004121]\n",
      "411 [D loss: 0.000383, acc.: 100.00%] [G loss: 0.006980]\n",
      "412 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.005285]\n",
      "413 [D loss: 0.000150, acc.: 100.00%] [G loss: 0.005219]\n",
      "414 [D loss: 0.000110, acc.: 100.00%] [G loss: 0.007333]\n",
      "415 [D loss: 0.000101, acc.: 100.00%] [G loss: 0.005700]\n",
      "416 [D loss: 0.000104, acc.: 100.00%] [G loss: 0.010535]\n",
      "417 [D loss: 0.000100, acc.: 100.00%] [G loss: 0.008214]\n",
      "418 [D loss: 0.000175, acc.: 100.00%] [G loss: 0.004763]\n",
      "419 [D loss: 0.000134, acc.: 100.00%] [G loss: 0.006678]\n",
      "420 [D loss: 0.000143, acc.: 100.00%] [G loss: 0.005084]\n",
      "421 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.003696]\n",
      "422 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.002179]\n",
      "423 [D loss: 0.000126, acc.: 100.00%] [G loss: 0.003047]\n",
      "424 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.002952]\n",
      "425 [D loss: 0.000125, acc.: 100.00%] [G loss: 0.003027]\n",
      "426 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.001828]\n",
      "427 [D loss: 0.000138, acc.: 100.00%] [G loss: 0.002231]\n",
      "428 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.001702]\n",
      "429 [D loss: 0.000134, acc.: 100.00%] [G loss: 0.003033]\n",
      "430 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.001438]\n",
      "431 [D loss: 0.000170, acc.: 100.00%] [G loss: 0.006115]\n",
      "432 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.004421]\n",
      "433 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.002678]\n",
      "434 [D loss: 0.000174, acc.: 100.00%] [G loss: 0.001963]\n",
      "435 [D loss: 0.000237, acc.: 100.00%] [G loss: 0.003508]\n",
      "436 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.002432]\n",
      "437 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.003116]\n",
      "438 [D loss: 0.000283, acc.: 100.00%] [G loss: 0.002430]\n",
      "439 [D loss: 0.000220, acc.: 100.00%] [G loss: 0.003617]\n",
      "440 [D loss: 0.000239, acc.: 100.00%] [G loss: 0.007953]\n",
      "441 [D loss: 0.000980, acc.: 100.00%] [G loss: 0.010810]\n",
      "442 [D loss: 0.000110, acc.: 100.00%] [G loss: 0.009031]\n",
      "443 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.007121]\n",
      "444 [D loss: 0.000205, acc.: 100.00%] [G loss: 0.009423]\n",
      "445 [D loss: 0.000120, acc.: 100.00%] [G loss: 0.008959]\n",
      "446 [D loss: 0.000147, acc.: 100.00%] [G loss: 0.009279]\n",
      "447 [D loss: 0.000197, acc.: 100.00%] [G loss: 0.009238]\n",
      "448 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.010071]\n",
      "449 [D loss: 0.000190, acc.: 100.00%] [G loss: 0.006711]\n",
      "450 [D loss: 0.000108, acc.: 100.00%] [G loss: 0.011045]\n",
      "451 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.006238]\n",
      "452 [D loss: 0.000210, acc.: 100.00%] [G loss: 0.009232]\n",
      "453 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.006112]\n",
      "454 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.005954]\n",
      "455 [D loss: 0.000187, acc.: 100.00%] [G loss: 0.007699]\n",
      "456 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.006466]\n",
      "457 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.006296]\n",
      "458 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.003815]\n",
      "459 [D loss: 0.000169, acc.: 100.00%] [G loss: 0.004737]\n",
      "460 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.001849]\n",
      "461 [D loss: 0.000083, acc.: 100.00%] [G loss: 0.001162]\n",
      "462 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.001697]\n",
      "463 [D loss: 0.000102, acc.: 100.00%] [G loss: 0.004569]\n",
      "464 [D loss: 0.000103, acc.: 100.00%] [G loss: 0.003992]\n",
      "465 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.004855]\n",
      "466 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.004644]\n",
      "467 [D loss: 0.000114, acc.: 100.00%] [G loss: 0.006770]\n",
      "468 [D loss: 0.000223, acc.: 100.00%] [G loss: 0.004492]\n",
      "469 [D loss: 0.000120, acc.: 100.00%] [G loss: 0.004641]\n",
      "470 [D loss: 0.000078, acc.: 100.00%] [G loss: 0.005818]\n",
      "471 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.006601]\n",
      "472 [D loss: 0.000356, acc.: 100.00%] [G loss: 0.006849]\n",
      "473 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.006903]\n",
      "474 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.005285]\n",
      "475 [D loss: 0.000222, acc.: 100.00%] [G loss: 0.006589]\n",
      "476 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.004242]\n",
      "477 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.005020]\n",
      "478 [D loss: 0.000089, acc.: 100.00%] [G loss: 0.003437]\n",
      "479 [D loss: 0.000103, acc.: 100.00%] [G loss: 0.002648]\n",
      "480 [D loss: 0.000077, acc.: 100.00%] [G loss: 0.002373]\n",
      "481 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.001538]\n",
      "482 [D loss: 0.000272, acc.: 100.00%] [G loss: 0.004660]\n",
      "483 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.006036]\n",
      "484 [D loss: 0.000126, acc.: 100.00%] [G loss: 0.004712]\n",
      "485 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.006483]\n",
      "486 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002423]\n",
      "487 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.001997]\n",
      "488 [D loss: 0.000111, acc.: 100.00%] [G loss: 0.004359]\n",
      "489 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.005864]\n",
      "490 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.008445]\n",
      "491 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.007067]\n",
      "492 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.002181]\n",
      "493 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.002002]\n",
      "494 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.002176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003979]\n",
      "496 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.002788]\n",
      "497 [D loss: 0.000083, acc.: 100.00%] [G loss: 0.004272]\n",
      "498 [D loss: 0.000473, acc.: 100.00%] [G loss: 0.008267]\n",
      "499 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.004161]\n",
      "500 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.003560]\n",
      "Generating interpolations...\n",
      "501 [D loss: 0.000780, acc.: 100.00%] [G loss: 0.013380]\n",
      "502 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.010188]\n",
      "503 [D loss: 0.000041, acc.: 100.00%] [G loss: 0.004764]\n",
      "504 [D loss: 0.002345, acc.: 100.00%] [G loss: 0.008197]\n",
      "505 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.003065]\n",
      "506 [D loss: 0.000305, acc.: 100.00%] [G loss: 0.010366]\n",
      "507 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.003733]\n",
      "508 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.004001]\n",
      "509 [D loss: 0.000160, acc.: 100.00%] [G loss: 0.001852]\n",
      "510 [D loss: 0.000133, acc.: 100.00%] [G loss: 0.001965]\n",
      "511 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.000900]\n",
      "512 [D loss: 0.000103, acc.: 100.00%] [G loss: 0.003236]\n",
      "513 [D loss: 0.000100, acc.: 100.00%] [G loss: 0.002002]\n",
      "514 [D loss: 0.000159, acc.: 100.00%] [G loss: 0.001733]\n",
      "515 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.001051]\n",
      "516 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.001753]\n",
      "517 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.002949]\n",
      "518 [D loss: 0.000084, acc.: 100.00%] [G loss: 0.002282]\n",
      "519 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.002055]\n",
      "520 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.001855]\n",
      "521 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.002441]\n",
      "522 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.001372]\n",
      "523 [D loss: 0.000078, acc.: 100.00%] [G loss: 0.001176]\n",
      "524 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001344]\n",
      "525 [D loss: 0.000107, acc.: 100.00%] [G loss: 0.001960]\n",
      "526 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.003200]\n",
      "527 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.002829]\n",
      "528 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.005015]\n",
      "529 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.002789]\n",
      "530 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002359]\n",
      "531 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.002912]\n",
      "532 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.003506]\n",
      "533 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.003567]\n",
      "534 [D loss: 0.000566, acc.: 100.00%] [G loss: 0.003514]\n",
      "535 [D loss: 0.000094, acc.: 100.00%] [G loss: 0.005037]\n",
      "536 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.003521]\n",
      "537 [D loss: 0.000119, acc.: 100.00%] [G loss: 0.004943]\n",
      "538 [D loss: 0.000115, acc.: 100.00%] [G loss: 0.003817]\n",
      "539 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.002695]\n",
      "540 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.000794]\n",
      "541 [D loss: 0.000095, acc.: 100.00%] [G loss: 0.001759]\n",
      "542 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.001610]\n",
      "543 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001193]\n",
      "544 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.001772]\n",
      "545 [D loss: 0.000114, acc.: 100.00%] [G loss: 0.002556]\n",
      "546 [D loss: 0.000143, acc.: 100.00%] [G loss: 0.002194]\n",
      "547 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.001190]\n",
      "548 [D loss: 0.000096, acc.: 100.00%] [G loss: 0.005063]\n",
      "549 [D loss: 0.000411, acc.: 100.00%] [G loss: 0.007853]\n",
      "550 [D loss: 0.000130, acc.: 100.00%] [G loss: 0.006648]\n",
      "551 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.004623]\n",
      "552 [D loss: 0.000197, acc.: 100.00%] [G loss: 0.008844]\n",
      "553 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.005905]\n",
      "554 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.004733]\n",
      "555 [D loss: 0.000162, acc.: 100.00%] [G loss: 0.007962]\n",
      "556 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.003893]\n",
      "557 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.002537]\n",
      "558 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002775]\n",
      "559 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001993]\n",
      "560 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.001065]\n",
      "561 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.002449]\n",
      "562 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.002647]\n",
      "563 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.003666]\n",
      "564 [D loss: 0.000080, acc.: 100.00%] [G loss: 0.003325]\n",
      "565 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.004584]\n",
      "566 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002487]\n",
      "567 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.002100]\n",
      "568 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002437]\n",
      "569 [D loss: 0.000105, acc.: 100.00%] [G loss: 0.003936]\n",
      "570 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.003079]\n",
      "571 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.002311]\n",
      "572 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.002167]\n",
      "573 [D loss: 0.000114, acc.: 100.00%] [G loss: 0.005115]\n",
      "574 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.006908]\n",
      "575 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001927]\n",
      "576 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.004340]\n",
      "577 [D loss: 0.000137, acc.: 100.00%] [G loss: 0.005444]\n",
      "578 [D loss: 0.000055, acc.: 100.00%] [G loss: 0.007766]\n",
      "579 [D loss: 0.000227, acc.: 100.00%] [G loss: 0.007515]\n",
      "580 [D loss: 0.000285, acc.: 100.00%] [G loss: 0.013000]\n",
      "581 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.007474]\n",
      "582 [D loss: 0.001684, acc.: 100.00%] [G loss: 0.013894]\n",
      "583 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.003772]\n",
      "584 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.002618]\n",
      "585 [D loss: 0.000164, acc.: 100.00%] [G loss: 0.004639]\n",
      "586 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.002579]\n",
      "587 [D loss: 0.000111, acc.: 100.00%] [G loss: 0.002912]\n",
      "588 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.002696]\n",
      "589 [D loss: 0.000090, acc.: 100.00%] [G loss: 0.003059]\n",
      "590 [D loss: 0.000190, acc.: 100.00%] [G loss: 0.003272]\n",
      "591 [D loss: 0.000087, acc.: 100.00%] [G loss: 0.004877]\n",
      "592 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001806]\n",
      "593 [D loss: 0.001556, acc.: 100.00%] [G loss: 0.010795]\n",
      "594 [D loss: 0.000117, acc.: 100.00%] [G loss: 0.003547]\n",
      "595 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003052]\n",
      "596 [D loss: 0.000327, acc.: 100.00%] [G loss: 0.003433]\n",
      "597 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.001890]\n",
      "598 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.001268]\n",
      "599 [D loss: 0.000156, acc.: 100.00%] [G loss: 0.000959]\n",
      "600 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.000731]\n",
      "Generating interpolations...\n",
      "601 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.001523]\n",
      "602 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.001116]\n",
      "603 [D loss: 0.000095, acc.: 100.00%] [G loss: 0.001151]\n",
      "604 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.001075]\n",
      "605 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.002813]\n",
      "606 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.006393]\n",
      "607 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.000946]\n",
      "608 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.002274]\n",
      "609 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001676]\n",
      "610 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.001685]\n",
      "611 [D loss: 0.000427, acc.: 100.00%] [G loss: 0.003995]\n",
      "612 [D loss: 0.000089, acc.: 100.00%] [G loss: 0.004181]\n",
      "613 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002145]\n",
      "614 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.001964]\n",
      "615 [D loss: 0.000098, acc.: 100.00%] [G loss: 0.002483]\n",
      "616 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.003370]\n",
      "617 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.003728]\n",
      "618 [D loss: 0.000084, acc.: 100.00%] [G loss: 0.004425]\n",
      "619 [D loss: 0.000134, acc.: 100.00%] [G loss: 0.007752]\n",
      "620 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.005610]\n",
      "621 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.004379]\n",
      "622 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002837]\n",
      "623 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.001906]\n",
      "624 [D loss: 0.000175, acc.: 100.00%] [G loss: 0.001329]\n",
      "625 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.001227]\n",
      "626 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.001317]\n",
      "627 [D loss: 0.000091, acc.: 100.00%] [G loss: 0.002107]\n",
      "628 [D loss: 0.000125, acc.: 100.00%] [G loss: 0.001924]\n",
      "629 [D loss: 0.000171, acc.: 100.00%] [G loss: 0.002448]\n",
      "630 [D loss: 0.000211, acc.: 100.00%] [G loss: 0.002315]\n",
      "631 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.004210]\n",
      "632 [D loss: 0.000116, acc.: 100.00%] [G loss: 0.008509]\n",
      "633 [D loss: 0.000129, acc.: 100.00%] [G loss: 0.006640]\n",
      "634 [D loss: 0.001151, acc.: 100.00%] [G loss: 0.011852]\n",
      "635 [D loss: 0.000149, acc.: 100.00%] [G loss: 0.011056]\n",
      "636 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.005108]\n",
      "637 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638 [D loss: 0.000106, acc.: 100.00%] [G loss: 0.002268]\n",
      "639 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.002748]\n",
      "640 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002260]\n",
      "641 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.001874]\n",
      "642 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.001480]\n",
      "643 [D loss: 0.000124, acc.: 100.00%] [G loss: 0.002511]\n",
      "644 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001595]\n",
      "645 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001726]\n",
      "646 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.001285]\n",
      "647 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001538]\n",
      "648 [D loss: 0.000511, acc.: 100.00%] [G loss: 0.004964]\n",
      "649 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.003084]\n",
      "650 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.003841]\n",
      "651 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.005484]\n",
      "652 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002347]\n",
      "653 [D loss: 0.000202, acc.: 100.00%] [G loss: 0.001082]\n",
      "654 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002934]\n",
      "655 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.002660]\n",
      "656 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.002015]\n",
      "657 [D loss: 0.000068, acc.: 100.00%] [G loss: 0.001960]\n",
      "658 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.000964]\n",
      "659 [D loss: 0.000214, acc.: 100.00%] [G loss: 0.002573]\n",
      "660 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.001701]\n",
      "661 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001657]\n",
      "662 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.003021]\n",
      "663 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.001186]\n",
      "664 [D loss: 0.000101, acc.: 100.00%] [G loss: 0.003433]\n",
      "665 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.001952]\n",
      "666 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.001444]\n",
      "667 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.002457]\n",
      "668 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002386]\n",
      "669 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001187]\n",
      "670 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.003274]\n",
      "671 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.001928]\n",
      "672 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.001707]\n",
      "673 [D loss: 0.000140, acc.: 100.00%] [G loss: 0.003526]\n",
      "674 [D loss: 0.000105, acc.: 100.00%] [G loss: 0.004707]\n",
      "675 [D loss: 0.000410, acc.: 100.00%] [G loss: 0.005376]\n",
      "676 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.003968]\n",
      "677 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002241]\n",
      "678 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.003013]\n",
      "679 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.002609]\n",
      "680 [D loss: 0.000391, acc.: 100.00%] [G loss: 0.006881]\n",
      "681 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.002649]\n",
      "682 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.002904]\n",
      "683 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.004605]\n",
      "684 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.004021]\n",
      "685 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.004009]\n",
      "686 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001583]\n",
      "687 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.001408]\n",
      "688 [D loss: 0.000090, acc.: 100.00%] [G loss: 0.001910]\n",
      "689 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.002203]\n",
      "690 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.000974]\n",
      "691 [D loss: 0.000149, acc.: 100.00%] [G loss: 0.003039]\n",
      "692 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.002079]\n",
      "693 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.001763]\n",
      "694 [D loss: 0.000135, acc.: 100.00%] [G loss: 0.003022]\n",
      "695 [D loss: 0.000424, acc.: 100.00%] [G loss: 0.007009]\n",
      "696 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.004541]\n",
      "697 [D loss: 0.000151, acc.: 100.00%] [G loss: 0.001768]\n",
      "698 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001112]\n",
      "699 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.001754]\n",
      "700 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002084]\n",
      "Generating interpolations...\n",
      "701 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002833]\n",
      "702 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.002426]\n",
      "703 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.001903]\n",
      "704 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.001330]\n",
      "705 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001074]\n",
      "706 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.001627]\n",
      "707 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.001584]\n",
      "708 [D loss: 0.000132, acc.: 100.00%] [G loss: 0.001341]\n",
      "709 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001333]\n",
      "710 [D loss: 0.000323, acc.: 100.00%] [G loss: 0.004133]\n",
      "711 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.003283]\n",
      "712 [D loss: 0.000093, acc.: 100.00%] [G loss: 0.002611]\n",
      "713 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000885]\n",
      "714 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000747]\n",
      "715 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.000756]\n",
      "716 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.001065]\n",
      "717 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000945]\n",
      "718 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.000807]\n",
      "719 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001632]\n",
      "720 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.002516]\n",
      "721 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.001737]\n",
      "722 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000750]\n",
      "723 [D loss: 0.000131, acc.: 100.00%] [G loss: 0.001631]\n",
      "724 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.003536]\n",
      "725 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001204]\n",
      "726 [D loss: 0.000096, acc.: 100.00%] [G loss: 0.001233]\n",
      "727 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000995]\n",
      "728 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001026]\n",
      "729 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000959]\n",
      "730 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001291]\n",
      "731 [D loss: 0.000234, acc.: 100.00%] [G loss: 0.003013]\n",
      "732 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002745]\n",
      "733 [D loss: 0.000136, acc.: 100.00%] [G loss: 0.004888]\n",
      "734 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.002923]\n",
      "735 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.003414]\n",
      "736 [D loss: 0.000988, acc.: 100.00%] [G loss: 0.008981]\n",
      "737 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.004923]\n",
      "738 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.002240]\n",
      "739 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.001240]\n",
      "740 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002139]\n",
      "741 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.002789]\n",
      "742 [D loss: 0.000095, acc.: 100.00%] [G loss: 0.004476]\n",
      "743 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002879]\n",
      "744 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001844]\n",
      "745 [D loss: 0.000140, acc.: 100.00%] [G loss: 0.003172]\n",
      "746 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001132]\n",
      "747 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.002502]\n",
      "748 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000944]\n",
      "749 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.000992]\n",
      "750 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.001681]\n",
      "751 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.001839]\n",
      "752 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.000611]\n",
      "753 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000746]\n",
      "754 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000333]\n",
      "755 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.000914]\n",
      "756 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.000839]\n",
      "757 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000739]\n",
      "758 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.001376]\n",
      "759 [D loss: 0.000088, acc.: 100.00%] [G loss: 0.004100]\n",
      "760 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001616]\n",
      "761 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001822]\n",
      "762 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.001336]\n",
      "763 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.001308]\n",
      "764 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.001746]\n",
      "765 [D loss: 0.000074, acc.: 100.00%] [G loss: 0.003384]\n",
      "766 [D loss: 0.000340, acc.: 100.00%] [G loss: 0.005267]\n",
      "767 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002108]\n",
      "768 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000878]\n",
      "769 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000346]\n",
      "770 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.000596]\n",
      "771 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.000941]\n",
      "772 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.002616]\n",
      "773 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.002125]\n",
      "774 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.002188]\n",
      "775 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002890]\n",
      "776 [D loss: 0.000089, acc.: 100.00%] [G loss: 0.002374]\n",
      "777 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.003119]\n",
      "778 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.002191]\n",
      "779 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.001424]\n",
      "780 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001063]\n",
      "781 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.001239]\n",
      "783 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.001645]\n",
      "784 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.003389]\n",
      "785 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001651]\n",
      "786 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001367]\n",
      "787 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.001033]\n",
      "788 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000625]\n",
      "789 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.001088]\n",
      "790 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.000842]\n",
      "791 [D loss: 0.000113, acc.: 100.00%] [G loss: 0.002486]\n",
      "792 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.002221]\n",
      "793 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001444]\n",
      "794 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001495]\n",
      "795 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001163]\n",
      "796 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.003535]\n",
      "797 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001883]\n",
      "798 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001534]\n",
      "799 [D loss: 0.000211, acc.: 100.00%] [G loss: 0.002538]\n",
      "800 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.002554]\n",
      "Generating interpolations...\n",
      "801 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001149]\n",
      "802 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001574]\n",
      "803 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.003618]\n",
      "804 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.003570]\n",
      "805 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.005960]\n",
      "806 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.003012]\n",
      "807 [D loss: 0.000077, acc.: 100.00%] [G loss: 0.000834]\n",
      "808 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.001468]\n",
      "809 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001940]\n",
      "810 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001678]\n",
      "811 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002493]\n",
      "812 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001788]\n",
      "813 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001402]\n",
      "814 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001665]\n",
      "815 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.001366]\n",
      "816 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001401]\n",
      "817 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000693]\n",
      "818 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000817]\n",
      "819 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.000652]\n",
      "820 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001027]\n",
      "821 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001958]\n",
      "822 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000899]\n",
      "823 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000693]\n",
      "824 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.001232]\n",
      "825 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000462]\n",
      "826 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000662]\n",
      "827 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001013]\n",
      "828 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001717]\n",
      "829 [D loss: 0.000128, acc.: 100.00%] [G loss: 0.007681]\n",
      "830 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.001832]\n",
      "831 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002007]\n",
      "832 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001218]\n",
      "833 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003076]\n",
      "834 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.004011]\n",
      "835 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.003699]\n",
      "836 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001372]\n",
      "837 [D loss: 0.000111, acc.: 100.00%] [G loss: 0.003056]\n",
      "838 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.004227]\n",
      "839 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.004813]\n",
      "840 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002965]\n",
      "841 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.004807]\n",
      "842 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.007115]\n",
      "843 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.002909]\n",
      "844 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.003206]\n",
      "845 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.003835]\n",
      "846 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001373]\n",
      "847 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.001469]\n",
      "848 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001441]\n",
      "849 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.001416]\n",
      "850 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001539]\n",
      "851 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001948]\n",
      "852 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.003072]\n",
      "853 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002618]\n",
      "854 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.004395]\n",
      "855 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.004151]\n",
      "856 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.003866]\n",
      "857 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001217]\n",
      "858 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.001288]\n",
      "859 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001636]\n",
      "860 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001800]\n",
      "861 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002166]\n",
      "862 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001898]\n",
      "863 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002878]\n",
      "864 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001936]\n",
      "865 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000787]\n",
      "866 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.001600]\n",
      "867 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002195]\n",
      "868 [D loss: 0.000204, acc.: 100.00%] [G loss: 0.002977]\n",
      "869 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.003243]\n",
      "870 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002028]\n",
      "871 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001436]\n",
      "872 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000704]\n",
      "873 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000771]\n",
      "874 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.001252]\n",
      "875 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002508]\n",
      "876 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001886]\n",
      "877 [D loss: 0.000242, acc.: 100.00%] [G loss: 0.005974]\n",
      "878 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.003585]\n",
      "879 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001734]\n",
      "880 [D loss: 0.000105, acc.: 100.00%] [G loss: 0.004599]\n",
      "881 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.002352]\n",
      "882 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002948]\n",
      "883 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.002366]\n",
      "884 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000413]\n",
      "885 [D loss: 0.000087, acc.: 100.00%] [G loss: 0.001741]\n",
      "886 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001088]\n",
      "887 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002318]\n",
      "888 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001063]\n",
      "889 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.001208]\n",
      "890 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001459]\n",
      "891 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000960]\n",
      "892 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001747]\n",
      "893 [D loss: 0.000221, acc.: 100.00%] [G loss: 0.003495]\n",
      "894 [D loss: 0.000152, acc.: 100.00%] [G loss: 0.004858]\n",
      "895 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.002325]\n",
      "896 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001254]\n",
      "897 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000916]\n",
      "898 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001038]\n",
      "899 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000880]\n",
      "900 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.001174]\n",
      "Generating interpolations...\n",
      "901 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000590]\n",
      "902 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000829]\n",
      "903 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.001982]\n",
      "904 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000703]\n",
      "905 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000516]\n",
      "906 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000712]\n",
      "907 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000421]\n",
      "908 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.001178]\n",
      "909 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.001324]\n",
      "910 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.001130]\n",
      "911 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001642]\n",
      "912 [D loss: 0.004771, acc.: 100.00%] [G loss: 0.001600]\n",
      "913 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.000896]\n",
      "914 [D loss: 0.000077, acc.: 100.00%] [G loss: 0.000487]\n",
      "915 [D loss: 0.000093, acc.: 100.00%] [G loss: 0.000102]\n",
      "916 [D loss: 0.000320, acc.: 100.00%] [G loss: 0.000271]\n",
      "917 [D loss: 0.000080, acc.: 100.00%] [G loss: 0.000172]\n",
      "918 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000146]\n",
      "919 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000201]\n",
      "920 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.000329]\n",
      "921 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.000120]\n",
      "922 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.000077]\n",
      "923 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.000314]\n",
      "924 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.000108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.000186]\n",
      "926 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.000553]\n",
      "927 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000553]\n",
      "928 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000265]\n",
      "929 [D loss: 0.000061, acc.: 100.00%] [G loss: 0.000089]\n",
      "930 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.000059]\n",
      "931 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.000245]\n",
      "932 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000433]\n",
      "933 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000497]\n",
      "934 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.000188]\n",
      "935 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000193]\n",
      "936 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.000106]\n",
      "937 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.000044]\n",
      "938 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.000166]\n",
      "939 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000081]\n",
      "940 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.000146]\n",
      "941 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.000150]\n",
      "942 [D loss: 0.000041, acc.: 100.00%] [G loss: 0.000204]\n",
      "943 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000215]\n",
      "944 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.000322]\n",
      "945 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000356]\n",
      "946 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000203]\n",
      "947 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.000081]\n",
      "948 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.000248]\n",
      "949 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.000309]\n",
      "950 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000145]\n",
      "951 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.000407]\n",
      "952 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000303]\n",
      "953 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000544]\n",
      "954 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.000962]\n",
      "955 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000987]\n",
      "956 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000423]\n",
      "957 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000535]\n",
      "958 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000298]\n",
      "959 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000182]\n",
      "960 [D loss: 0.000181, acc.: 100.00%] [G loss: 0.000797]\n",
      "961 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.000479]\n",
      "962 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000536]\n",
      "963 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.000241]\n",
      "964 [D loss: 0.000158, acc.: 100.00%] [G loss: 0.000436]\n",
      "965 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000745]\n",
      "966 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000407]\n",
      "967 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.000419]\n",
      "968 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000313]\n",
      "969 [D loss: 0.000043, acc.: 100.00%] [G loss: 0.000266]\n",
      "970 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.000207]\n",
      "971 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.000088]\n",
      "972 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000127]\n",
      "973 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000104]\n",
      "974 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000113]\n",
      "975 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000060]\n",
      "976 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000119]\n",
      "977 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000054]\n",
      "978 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000133]\n",
      "979 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000086]\n",
      "980 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000062]\n",
      "981 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.000128]\n",
      "982 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000064]\n",
      "983 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000069]\n",
      "984 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000086]\n",
      "985 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.000277]\n",
      "986 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000212]\n",
      "987 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.000723]\n",
      "988 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000351]\n",
      "989 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000186]\n",
      "990 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000236]\n",
      "991 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000421]\n",
      "992 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.000112]\n",
      "993 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.000100]\n",
      "994 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000261]\n",
      "995 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000645]\n",
      "996 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.001034]\n",
      "997 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000378]\n",
      "998 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.000509]\n",
      "999 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000592]\n",
      "1000 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000255]\n",
      "Generating interpolations...\n",
      "1001 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.000497]\n",
      "1002 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.000100]\n",
      "1003 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000301]\n",
      "1004 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000444]\n",
      "1005 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000372]\n",
      "1006 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.000368]\n",
      "1007 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001109]\n",
      "1008 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000236]\n",
      "1009 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000326]\n",
      "1010 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000428]\n",
      "1011 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000345]\n",
      "1012 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000507]\n",
      "1013 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001601]\n",
      "1014 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000878]\n",
      "1015 [D loss: 0.000098, acc.: 100.00%] [G loss: 0.001696]\n",
      "1016 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.002627]\n",
      "1017 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000300]\n",
      "1018 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000480]\n",
      "1019 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000210]\n",
      "1020 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.000244]\n",
      "1021 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000277]\n",
      "1022 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000333]\n",
      "1023 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000280]\n",
      "1024 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000341]\n",
      "1025 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000243]\n",
      "1026 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000262]\n",
      "1027 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000488]\n",
      "1028 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.000329]\n",
      "1029 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000504]\n",
      "1030 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000274]\n",
      "1031 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000168]\n",
      "1032 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000738]\n",
      "1033 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000583]\n",
      "1034 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000379]\n",
      "1035 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000111]\n",
      "1036 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000088]\n",
      "1037 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.000088]\n",
      "1038 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000146]\n",
      "1039 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000411]\n",
      "1040 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000315]\n",
      "1041 [D loss: 0.000088, acc.: 100.00%] [G loss: 0.001313]\n",
      "1042 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000449]\n",
      "1043 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000141]\n",
      "1044 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000195]\n",
      "1045 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000260]\n",
      "1046 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000435]\n",
      "1047 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000710]\n",
      "1048 [D loss: 0.000162, acc.: 100.00%] [G loss: 0.001113]\n",
      "1049 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.002454]\n",
      "1050 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.002312]\n",
      "1051 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000499]\n",
      "1052 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001519]\n",
      "1053 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001200]\n",
      "1054 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.000891]\n",
      "1055 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000419]\n",
      "1056 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000139]\n",
      "1057 [D loss: 0.000108, acc.: 100.00%] [G loss: 0.000842]\n",
      "1058 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000494]\n",
      "1059 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000770]\n",
      "1060 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000662]\n",
      "1061 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.000710]\n",
      "1062 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000397]\n",
      "1063 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000189]\n",
      "1064 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000160]\n",
      "1065 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000256]\n",
      "1066 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.000961]\n",
      "1067 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000674]\n",
      "1069 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000693]\n",
      "1070 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000236]\n",
      "1071 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000219]\n",
      "1072 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000223]\n",
      "1073 [D loss: 0.000301, acc.: 100.00%] [G loss: 0.000954]\n",
      "1074 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000898]\n",
      "1075 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000676]\n",
      "1076 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000791]\n",
      "1077 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000610]\n",
      "1078 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.001260]\n",
      "1079 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000297]\n",
      "1080 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000631]\n",
      "1081 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000380]\n",
      "1082 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000287]\n",
      "1083 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000522]\n",
      "1084 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000409]\n",
      "1085 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000792]\n",
      "1086 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.001905]\n",
      "1087 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001121]\n",
      "1088 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000603]\n",
      "1089 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000798]\n",
      "1090 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001158]\n",
      "1091 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000713]\n",
      "1092 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000787]\n",
      "1093 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000216]\n",
      "1094 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000225]\n",
      "1095 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000281]\n",
      "1096 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.000520]\n",
      "1097 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000708]\n",
      "1098 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.001041]\n",
      "1099 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000701]\n",
      "1100 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001296]\n",
      "Generating interpolations...\n",
      "1101 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000789]\n",
      "1102 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000386]\n",
      "1103 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000352]\n",
      "1104 [D loss: 0.000701, acc.: 100.00%] [G loss: 0.001595]\n",
      "1105 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000195]\n",
      "1106 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000175]\n",
      "1107 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.000592]\n",
      "1108 [D loss: 0.000094, acc.: 100.00%] [G loss: 0.001479]\n",
      "1109 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001627]\n",
      "1110 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.000873]\n",
      "1111 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000312]\n",
      "1112 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000266]\n",
      "1113 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000158]\n",
      "1114 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000301]\n",
      "1115 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000191]\n",
      "1116 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000307]\n",
      "1117 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000479]\n",
      "1118 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000406]\n",
      "1119 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000418]\n",
      "1120 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000446]\n",
      "1121 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000562]\n",
      "1122 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.000253]\n",
      "1123 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000541]\n",
      "1124 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000804]\n",
      "1125 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000781]\n",
      "1126 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000799]\n",
      "1127 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001198]\n",
      "1128 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000681]\n",
      "1129 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000542]\n",
      "1130 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000560]\n",
      "1131 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000371]\n",
      "1132 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000097]\n",
      "1133 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000206]\n",
      "1134 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000501]\n",
      "1135 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000546]\n",
      "1136 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000443]\n",
      "1137 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000605]\n",
      "1138 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000743]\n",
      "1139 [D loss: 0.000249, acc.: 100.00%] [G loss: 0.001689]\n",
      "1140 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000832]\n",
      "1141 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000792]\n",
      "1142 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001534]\n",
      "1143 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001053]\n",
      "1144 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000600]\n",
      "1145 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000600]\n",
      "1146 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000526]\n",
      "1147 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000147]\n",
      "1148 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000094]\n",
      "1149 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000079]\n",
      "1150 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000179]\n",
      "1151 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000208]\n",
      "1152 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000255]\n",
      "1153 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000351]\n",
      "1154 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000452]\n",
      "1155 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000491]\n",
      "1156 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000699]\n",
      "1157 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000537]\n",
      "1158 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000390]\n",
      "1159 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000657]\n",
      "1160 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000227]\n",
      "1161 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000476]\n",
      "1162 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000700]\n",
      "1163 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000636]\n",
      "1164 [D loss: 0.000091, acc.: 100.00%] [G loss: 0.002607]\n",
      "1165 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001271]\n",
      "1166 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001306]\n",
      "1167 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000982]\n",
      "1168 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001454]\n",
      "1169 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.003211]\n",
      "1170 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001357]\n",
      "1171 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000502]\n",
      "1172 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000735]\n",
      "1173 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000772]\n",
      "1174 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000759]\n",
      "1175 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000857]\n",
      "1176 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000503]\n",
      "1177 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000599]\n",
      "1178 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000473]\n",
      "1179 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000427]\n",
      "1180 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000870]\n",
      "1181 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001468]\n",
      "1182 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000939]\n",
      "1183 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.000483]\n",
      "1184 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.003273]\n",
      "1185 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.002300]\n",
      "1186 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.002684]\n",
      "1187 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000860]\n",
      "1188 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000285]\n",
      "1189 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000264]\n",
      "1190 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000665]\n",
      "1191 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000440]\n",
      "1192 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000564]\n",
      "1193 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000465]\n",
      "1194 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000701]\n",
      "1195 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000951]\n",
      "1196 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000318]\n",
      "1197 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000152]\n",
      "1198 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000248]\n",
      "1199 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000186]\n",
      "1200 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000344]\n",
      "Generating interpolations...\n",
      "1201 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000614]\n",
      "1202 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000718]\n",
      "1203 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000973]\n",
      "1204 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.001393]\n",
      "1205 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001991]\n",
      "1206 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000750]\n",
      "1207 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.001572]\n",
      "1208 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1209 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000707]\n",
      "1210 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000531]\n",
      "1211 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000419]\n",
      "1212 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000280]\n",
      "1213 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000690]\n",
      "1214 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000991]\n",
      "1215 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000912]\n",
      "1216 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001020]\n",
      "1217 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000477]\n",
      "1218 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000735]\n",
      "1219 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000949]\n",
      "1220 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000596]\n",
      "1221 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000406]\n",
      "1222 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000174]\n",
      "1223 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000216]\n",
      "1224 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000154]\n",
      "1225 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000410]\n",
      "1226 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.000392]\n",
      "1227 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000341]\n",
      "1228 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000444]\n",
      "1229 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000767]\n",
      "1230 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000336]\n",
      "1231 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000486]\n",
      "1232 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000173]\n",
      "1233 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000393]\n",
      "1234 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000336]\n",
      "1235 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.001377]\n",
      "1236 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000942]\n",
      "1237 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.001763]\n",
      "1238 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001251]\n",
      "1239 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001687]\n",
      "1240 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000900]\n",
      "1241 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000615]\n",
      "1242 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001506]\n",
      "1243 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001176]\n",
      "1244 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000200]\n",
      "1245 [D loss: 0.000088, acc.: 100.00%] [G loss: 0.000667]\n",
      "1246 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000645]\n",
      "1247 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001257]\n",
      "1248 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001088]\n",
      "1249 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000522]\n",
      "1250 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000415]\n",
      "1251 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000184]\n",
      "1252 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000263]\n",
      "1253 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000340]\n",
      "1254 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000674]\n",
      "1255 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000660]\n",
      "1256 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001267]\n",
      "1257 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000749]\n",
      "1258 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000422]\n",
      "1259 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000320]\n",
      "1260 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000186]\n",
      "1261 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000545]\n",
      "1262 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000360]\n",
      "1263 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000263]\n",
      "1264 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000412]\n",
      "1265 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000291]\n",
      "1266 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000395]\n",
      "1267 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000200]\n",
      "1268 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000223]\n",
      "1269 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000387]\n",
      "1270 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000624]\n",
      "1271 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000928]\n",
      "1272 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000477]\n",
      "1273 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000352]\n",
      "1274 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000322]\n",
      "1275 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000553]\n",
      "1276 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000468]\n",
      "1277 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000547]\n",
      "1278 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000200]\n",
      "1279 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000254]\n",
      "1280 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000684]\n",
      "1281 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000688]\n",
      "1282 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000895]\n",
      "1283 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000726]\n",
      "1284 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001367]\n",
      "1285 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000838]\n",
      "1286 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000411]\n",
      "1287 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.001367]\n",
      "1288 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.002454]\n",
      "1289 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.002609]\n",
      "1290 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002260]\n",
      "1291 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.004341]\n",
      "1292 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001795]\n",
      "1293 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000911]\n",
      "1294 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000363]\n",
      "1295 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000660]\n",
      "1296 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000605]\n",
      "1297 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001242]\n",
      "1298 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000735]\n",
      "1299 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000587]\n",
      "1300 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000483]\n",
      "Generating interpolations...\n",
      "1301 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000645]\n",
      "1302 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000788]\n",
      "1303 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000908]\n",
      "1304 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000898]\n",
      "1305 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001330]\n",
      "1306 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000588]\n",
      "1307 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000733]\n",
      "1308 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000359]\n",
      "1309 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001058]\n",
      "1310 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000304]\n",
      "1311 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.000897]\n",
      "1312 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000998]\n",
      "1313 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000531]\n",
      "1314 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000735]\n",
      "1315 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000452]\n",
      "1316 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000482]\n",
      "1317 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000843]\n",
      "1318 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000944]\n",
      "1319 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000757]\n",
      "1320 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000384]\n",
      "1321 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000744]\n",
      "1322 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000462]\n",
      "1323 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000390]\n",
      "1324 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000365]\n",
      "1325 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000634]\n",
      "1326 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000459]\n",
      "1327 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000439]\n",
      "1328 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000372]\n",
      "1329 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002204]\n",
      "1330 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001030]\n",
      "1331 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001434]\n",
      "1332 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000589]\n",
      "1333 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000499]\n",
      "1334 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001929]\n",
      "1335 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001265]\n",
      "1336 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000680]\n",
      "1337 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000522]\n",
      "1338 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000381]\n",
      "1339 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000448]\n",
      "1340 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000681]\n",
      "1341 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001487]\n",
      "1342 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000820]\n",
      "1343 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000460]\n",
      "1344 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000734]\n",
      "1345 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000856]\n",
      "1346 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001081]\n",
      "1347 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000521]\n",
      "1348 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000473]\n",
      "1349 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000635]\n",
      "1351 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000825]\n",
      "1352 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000969]\n",
      "1353 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001506]\n",
      "1354 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001205]\n",
      "1355 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001646]\n",
      "1356 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001565]\n",
      "1357 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000342]\n",
      "1358 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000603]\n",
      "1359 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000319]\n",
      "1360 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000312]\n",
      "1361 [D loss: 0.000124, acc.: 100.00%] [G loss: 0.001399]\n",
      "1362 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001862]\n",
      "1363 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000503]\n",
      "1364 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000412]\n",
      "1365 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000855]\n",
      "1366 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.001371]\n",
      "1367 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000998]\n",
      "1368 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000733]\n",
      "1369 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.001778]\n",
      "1370 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.001594]\n",
      "1371 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.001082]\n",
      "1372 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000558]\n",
      "1373 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000528]\n",
      "1374 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.001857]\n",
      "1375 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001382]\n",
      "1376 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000729]\n",
      "1377 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001802]\n",
      "1378 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001622]\n",
      "1379 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000153]\n",
      "1380 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000308]\n",
      "1381 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000134]\n",
      "1382 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000199]\n",
      "1383 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000074]\n",
      "1384 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000211]\n",
      "1385 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000250]\n",
      "1386 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000200]\n",
      "1387 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000438]\n",
      "1388 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000256]\n",
      "1389 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000269]\n",
      "1390 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000546]\n",
      "1391 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000451]\n",
      "1392 [D loss: 0.000482, acc.: 100.00%] [G loss: 0.002065]\n",
      "1393 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002304]\n",
      "1394 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000911]\n",
      "1395 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000377]\n",
      "1396 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000316]\n",
      "1397 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000464]\n",
      "1398 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000412]\n",
      "1399 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000174]\n",
      "1400 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000097]\n",
      "Generating interpolations...\n",
      "1401 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000197]\n",
      "1402 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000173]\n",
      "1403 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000175]\n",
      "1404 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000332]\n",
      "1405 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000550]\n",
      "1406 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000574]\n",
      "1407 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001212]\n",
      "1408 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.002151]\n",
      "1409 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000638]\n",
      "1410 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000971]\n",
      "1411 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000491]\n",
      "1412 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000497]\n",
      "1413 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000959]\n",
      "1414 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000212]\n",
      "1415 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000178]\n",
      "1416 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000562]\n",
      "1417 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001166]\n",
      "1418 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000425]\n",
      "1419 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000366]\n",
      "1420 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000404]\n",
      "1421 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000326]\n",
      "1422 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000306]\n",
      "1423 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000177]\n",
      "1424 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000258]\n",
      "1425 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000860]\n",
      "1426 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000969]\n",
      "1427 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000166]\n",
      "1428 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000168]\n",
      "1429 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000197]\n",
      "1430 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.000414]\n",
      "1431 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000449]\n",
      "1432 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000372]\n",
      "1433 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000667]\n",
      "1434 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000325]\n",
      "1435 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000504]\n",
      "1436 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000552]\n",
      "1437 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002001]\n",
      "1438 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.003293]\n",
      "1439 [D loss: 0.000714, acc.: 100.00%] [G loss: 0.010940]\n",
      "1440 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.005243]\n",
      "1441 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001061]\n",
      "1442 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.002424]\n",
      "1443 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001423]\n",
      "1444 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000842]\n",
      "1445 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000623]\n",
      "1446 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000297]\n",
      "1447 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000558]\n",
      "1448 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000891]\n",
      "1449 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000248]\n",
      "1450 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000456]\n",
      "1451 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000360]\n",
      "1452 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000423]\n",
      "1453 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000354]\n",
      "1454 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000416]\n",
      "1455 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000518]\n",
      "1456 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000223]\n",
      "1457 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000194]\n",
      "1458 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000190]\n",
      "1459 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000157]\n",
      "1460 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000335]\n",
      "1461 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000167]\n",
      "1462 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000347]\n",
      "1463 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000497]\n",
      "1464 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000485]\n",
      "1465 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000383]\n",
      "1466 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000396]\n",
      "1467 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000279]\n",
      "1468 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000706]\n",
      "1469 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000859]\n",
      "1470 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000292]\n",
      "1471 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000235]\n",
      "1472 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000596]\n",
      "1473 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000347]\n",
      "1474 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000209]\n",
      "1475 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000588]\n",
      "1476 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000623]\n",
      "1477 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000168]\n",
      "1478 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000298]\n",
      "1479 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000491]\n",
      "1480 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000217]\n",
      "1481 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000307]\n",
      "1482 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000259]\n",
      "1483 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000214]\n",
      "1484 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000214]\n",
      "1485 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000243]\n",
      "1486 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000281]\n",
      "1487 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000282]\n",
      "1488 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001158]\n",
      "1489 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000511]\n",
      "1490 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000531]\n",
      "1492 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000499]\n",
      "1493 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000534]\n",
      "1494 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000230]\n",
      "1495 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000340]\n",
      "1496 [D loss: 0.000557, acc.: 100.00%] [G loss: 0.001170]\n",
      "1497 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000368]\n",
      "1498 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000221]\n",
      "1499 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000336]\n",
      "1500 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000165]\n",
      "Generating interpolations...\n",
      "1501 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000168]\n",
      "1502 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000185]\n",
      "1503 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000234]\n",
      "1504 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000091]\n",
      "1505 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000161]\n",
      "1506 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000258]\n",
      "1507 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000626]\n",
      "1508 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000432]\n",
      "1509 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000270]\n",
      "1510 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000339]\n",
      "1511 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000327]\n",
      "1512 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000297]\n",
      "1513 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000629]\n",
      "1514 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000140]\n",
      "1515 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000208]\n",
      "1516 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000590]\n",
      "1517 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000765]\n",
      "1518 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001241]\n",
      "1519 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000534]\n",
      "1520 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000236]\n",
      "1521 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000137]\n",
      "1522 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000359]\n",
      "1523 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000190]\n",
      "1524 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000104]\n",
      "1525 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000099]\n",
      "1526 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000371]\n",
      "1527 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000289]\n",
      "1528 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000271]\n",
      "1529 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000506]\n",
      "1530 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000535]\n",
      "1531 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000141]\n",
      "1532 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000191]\n",
      "1533 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000212]\n",
      "1534 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.000642]\n",
      "1535 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001020]\n",
      "1536 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001210]\n",
      "1537 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001242]\n",
      "1538 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001090]\n",
      "1539 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001219]\n",
      "1540 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001741]\n",
      "1541 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000916]\n",
      "1542 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000927]\n",
      "1543 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000457]\n",
      "1544 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000344]\n",
      "1545 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000229]\n",
      "1546 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000172]\n",
      "1547 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000090]\n",
      "1548 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000169]\n",
      "1549 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000571]\n",
      "1550 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000223]\n",
      "1551 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000864]\n",
      "1552 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000556]\n",
      "1553 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000658]\n",
      "1554 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000180]\n",
      "1555 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000420]\n",
      "1556 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000228]\n",
      "1557 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000099]\n",
      "1558 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000117]\n",
      "1559 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000133]\n",
      "1560 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000289]\n",
      "1561 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000464]\n",
      "1562 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001154]\n",
      "1563 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001017]\n",
      "1564 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000549]\n",
      "1565 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000364]\n",
      "1566 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000306]\n",
      "1567 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000528]\n",
      "1568 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000805]\n",
      "1569 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000754]\n",
      "1570 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000419]\n",
      "1571 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000316]\n",
      "1572 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000421]\n",
      "1573 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000993]\n",
      "1574 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000512]\n",
      "1575 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000699]\n",
      "1576 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000417]\n",
      "1577 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000523]\n",
      "1578 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000196]\n",
      "1579 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000217]\n",
      "1580 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000332]\n",
      "1581 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000384]\n",
      "1582 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000225]\n",
      "1583 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000294]\n",
      "1584 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000195]\n",
      "1585 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000329]\n",
      "1586 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000100]\n",
      "1587 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000113]\n",
      "1588 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000306]\n",
      "1589 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000358]\n",
      "1590 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000114]\n",
      "1591 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000091]\n",
      "1592 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.000647]\n",
      "1593 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000698]\n",
      "1594 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000451]\n",
      "1595 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000241]\n",
      "1596 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001386]\n",
      "1597 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000467]\n",
      "1598 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000166]\n",
      "1599 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000314]\n",
      "1600 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000228]\n",
      "Generating interpolations...\n",
      "1601 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000135]\n",
      "1602 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000119]\n",
      "1603 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000158]\n",
      "1604 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000271]\n",
      "1605 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000357]\n",
      "1606 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000307]\n",
      "1607 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000783]\n",
      "1608 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000746]\n",
      "1609 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000224]\n",
      "1610 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000441]\n",
      "1611 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000230]\n",
      "1612 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000263]\n",
      "1613 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000265]\n",
      "1614 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000142]\n",
      "1615 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000275]\n",
      "1616 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000550]\n",
      "1617 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000259]\n",
      "1618 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000235]\n",
      "1619 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000535]\n",
      "1620 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000250]\n",
      "1621 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000144]\n",
      "1622 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000138]\n",
      "1623 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000376]\n",
      "1624 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000558]\n",
      "1625 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000548]\n",
      "1626 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000381]\n",
      "1627 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000693]\n",
      "1628 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000372]\n",
      "1629 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000263]\n",
      "1630 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000299]\n",
      "1631 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000792]\n",
      "1633 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001791]\n",
      "1634 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001939]\n",
      "1635 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000827]\n",
      "1636 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001788]\n",
      "1637 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.002685]\n",
      "1638 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000484]\n",
      "1639 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000826]\n",
      "1640 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000473]\n",
      "1641 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000603]\n",
      "1642 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000624]\n",
      "1643 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000437]\n",
      "1644 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000520]\n",
      "1645 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000320]\n",
      "1646 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000186]\n",
      "1647 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000323]\n",
      "1648 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000730]\n",
      "1649 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000199]\n",
      "1650 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000427]\n",
      "1651 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000602]\n",
      "1652 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000453]\n",
      "1653 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000245]\n",
      "1654 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000198]\n",
      "1655 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000311]\n",
      "1656 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000145]\n",
      "1657 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000318]\n",
      "1658 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000384]\n",
      "1659 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000503]\n",
      "1660 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000620]\n",
      "1661 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000788]\n",
      "1662 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000663]\n",
      "1663 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000642]\n",
      "1664 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000483]\n",
      "1665 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000435]\n",
      "1666 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000391]\n",
      "1667 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000435]\n",
      "1668 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000521]\n",
      "1669 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000538]\n",
      "1670 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002170]\n",
      "1671 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001339]\n",
      "1672 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.002195]\n",
      "1673 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001093]\n",
      "1674 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000966]\n",
      "1675 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000782]\n",
      "1676 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000477]\n",
      "1677 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000926]\n",
      "1678 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.002236]\n",
      "1679 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000829]\n",
      "1680 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000393]\n",
      "1681 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000321]\n",
      "1682 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000757]\n",
      "1683 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000441]\n",
      "1684 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000613]\n",
      "1685 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000334]\n",
      "1686 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001081]\n",
      "1687 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000236]\n",
      "1688 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000323]\n",
      "1689 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000637]\n",
      "1690 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000388]\n",
      "1691 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000432]\n",
      "1692 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001215]\n",
      "1693 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001042]\n",
      "1694 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000790]\n",
      "1695 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001492]\n",
      "1696 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000437]\n",
      "1697 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000727]\n",
      "1698 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000379]\n",
      "1699 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000311]\n",
      "1700 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000353]\n",
      "Generating interpolations...\n",
      "1701 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000290]\n",
      "1702 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000431]\n",
      "1703 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000316]\n",
      "1704 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000245]\n",
      "1705 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000435]\n",
      "1706 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.001258]\n",
      "1707 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000448]\n",
      "1708 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000330]\n",
      "1709 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000295]\n",
      "1710 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000154]\n",
      "1711 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000500]\n",
      "1712 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000155]\n",
      "1713 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000953]\n",
      "1714 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000572]\n",
      "1715 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000294]\n",
      "1716 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000231]\n",
      "1717 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000168]\n",
      "1718 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000118]\n",
      "1719 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000065]\n",
      "1720 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000277]\n",
      "1721 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000166]\n",
      "1722 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000272]\n",
      "1723 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000280]\n",
      "1724 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000673]\n",
      "1725 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000362]\n",
      "1726 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000282]\n",
      "1727 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000915]\n",
      "1728 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001881]\n",
      "1729 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000617]\n",
      "1730 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000402]\n",
      "1731 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000522]\n",
      "1732 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000519]\n",
      "1733 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000447]\n",
      "1734 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000714]\n",
      "1735 [D loss: 0.000041, acc.: 100.00%] [G loss: 0.001886]\n",
      "1736 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000494]\n",
      "1737 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000177]\n",
      "1738 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000155]\n",
      "1739 [D loss: 0.000159, acc.: 100.00%] [G loss: 0.001430]\n",
      "1740 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001969]\n",
      "1741 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.002565]\n",
      "1742 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.002393]\n",
      "1743 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.002171]\n",
      "1744 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.001104]\n",
      "1745 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000834]\n",
      "1746 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000609]\n",
      "1747 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001058]\n",
      "1748 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000844]\n",
      "1749 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000289]\n",
      "1750 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000277]\n",
      "1751 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000283]\n",
      "1752 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000260]\n",
      "1753 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000230]\n",
      "1754 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000295]\n",
      "1755 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000805]\n",
      "1756 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000428]\n",
      "1757 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000435]\n",
      "1758 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000695]\n",
      "1759 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000720]\n",
      "1760 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000551]\n",
      "1761 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000590]\n",
      "1762 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000314]\n",
      "1763 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000293]\n",
      "1764 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000292]\n",
      "1765 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000170]\n",
      "1766 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000203]\n",
      "1767 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000446]\n",
      "1768 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000498]\n",
      "1769 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000731]\n",
      "1770 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001087]\n",
      "1771 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000632]\n",
      "1772 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000727]\n",
      "1774 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000234]\n",
      "1775 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000190]\n",
      "1776 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000166]\n",
      "1777 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000203]\n",
      "1778 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000270]\n",
      "1779 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000436]\n",
      "1780 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000483]\n",
      "1781 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000425]\n",
      "1782 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000867]\n",
      "1783 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000939]\n",
      "1784 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000382]\n",
      "1785 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000305]\n",
      "1786 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000228]\n",
      "1787 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000340]\n",
      "1788 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000225]\n",
      "1789 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000064]\n",
      "1790 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000126]\n",
      "1791 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000197]\n",
      "1792 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000975]\n",
      "1793 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000143]\n",
      "1794 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000190]\n",
      "1795 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000192]\n",
      "1796 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000397]\n",
      "1797 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000506]\n",
      "1798 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000740]\n",
      "1799 [D loss: 0.000180, acc.: 100.00%] [G loss: 0.001854]\n",
      "1800 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000509]\n",
      "Generating interpolations...\n",
      "1801 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000443]\n",
      "1802 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000226]\n",
      "1803 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000387]\n",
      "1804 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000987]\n",
      "1805 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000137]\n",
      "1806 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000159]\n",
      "1807 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000476]\n",
      "1808 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000201]\n",
      "1809 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000126]\n",
      "1810 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000196]\n",
      "1811 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000078]\n",
      "1812 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000134]\n",
      "1813 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000420]\n",
      "1814 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000191]\n",
      "1815 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000172]\n",
      "1816 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000594]\n",
      "1817 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000402]\n",
      "1818 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000379]\n",
      "1819 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000265]\n",
      "1820 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000511]\n",
      "1821 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000212]\n",
      "1822 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000126]\n",
      "1823 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000242]\n",
      "1824 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000331]\n",
      "1825 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000500]\n",
      "1826 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000754]\n",
      "1827 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001504]\n",
      "1828 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000807]\n",
      "1829 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000648]\n",
      "1830 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000450]\n",
      "1831 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000446]\n",
      "1832 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000251]\n",
      "1833 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000343]\n",
      "1834 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000180]\n",
      "1835 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000177]\n",
      "1836 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000124]\n",
      "1837 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000209]\n",
      "1838 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000286]\n",
      "1839 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000168]\n",
      "1840 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000213]\n",
      "1841 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000812]\n",
      "1842 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.001097]\n",
      "1843 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000724]\n",
      "1844 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000889]\n",
      "1845 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000500]\n",
      "1846 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000373]\n",
      "1847 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000203]\n",
      "1848 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000489]\n",
      "1849 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000280]\n",
      "1850 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000459]\n",
      "1851 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000319]\n",
      "1852 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000349]\n",
      "1853 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000414]\n",
      "1854 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000442]\n",
      "1855 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000422]\n",
      "1856 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000293]\n",
      "1857 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000106]\n",
      "1858 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000087]\n",
      "1859 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000220]\n",
      "1860 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000211]\n",
      "1861 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000552]\n",
      "1862 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000347]\n",
      "1863 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000130]\n",
      "1864 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000142]\n",
      "1865 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000263]\n",
      "1866 [D loss: 0.000182, acc.: 100.00%] [G loss: 0.001725]\n",
      "1867 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000749]\n",
      "1868 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000885]\n",
      "1869 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000470]\n",
      "1870 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000408]\n",
      "1871 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000549]\n",
      "1872 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000282]\n",
      "1873 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000188]\n",
      "1874 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000377]\n",
      "1875 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000172]\n",
      "1876 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000494]\n",
      "1877 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000224]\n",
      "1878 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000286]\n",
      "1879 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000535]\n",
      "1880 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002661]\n",
      "1881 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001027]\n",
      "1882 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000356]\n",
      "1883 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000236]\n",
      "1884 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000263]\n",
      "1885 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001238]\n",
      "1886 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001442]\n",
      "1887 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000728]\n",
      "1888 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000724]\n",
      "1889 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000798]\n",
      "1890 [D loss: 0.000120, acc.: 100.00%] [G loss: 0.002937]\n",
      "1891 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000866]\n",
      "1892 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000783]\n",
      "1893 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000585]\n",
      "1894 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000668]\n",
      "1895 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000536]\n",
      "1896 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000732]\n",
      "1897 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000682]\n",
      "1898 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000860]\n",
      "1899 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000327]\n",
      "1900 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000264]\n",
      "Generating interpolations...\n",
      "1901 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000297]\n",
      "1902 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000128]\n",
      "1903 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000127]\n",
      "1904 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000155]\n",
      "1905 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000093]\n",
      "1906 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000067]\n",
      "1907 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000480]\n",
      "1908 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000318]\n",
      "1909 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000278]\n",
      "1910 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000333]\n",
      "1911 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000239]\n",
      "1912 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000142]\n",
      "1913 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000360]\n",
      "1915 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000164]\n",
      "1916 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000324]\n",
      "1917 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000260]\n",
      "1918 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000182]\n",
      "1919 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000237]\n",
      "1920 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000108]\n",
      "1921 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000288]\n",
      "1922 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000428]\n",
      "1923 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000752]\n",
      "1924 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001132]\n",
      "1925 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000767]\n",
      "1926 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000830]\n",
      "1927 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000373]\n",
      "1928 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000792]\n",
      "1929 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000321]\n",
      "1930 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000562]\n",
      "1931 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000245]\n",
      "1932 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000438]\n",
      "1933 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000347]\n",
      "1934 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000273]\n",
      "1935 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000561]\n",
      "1936 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000569]\n",
      "1937 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001217]\n",
      "1938 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.002334]\n",
      "1939 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000448]\n",
      "1940 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000161]\n",
      "1941 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000415]\n",
      "1942 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000163]\n",
      "1943 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000235]\n",
      "1944 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000260]\n",
      "1945 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000400]\n",
      "1946 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000244]\n",
      "1947 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000366]\n",
      "1948 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000192]\n",
      "1949 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000414]\n",
      "1950 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000985]\n",
      "1951 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000279]\n",
      "1952 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000205]\n",
      "1953 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000151]\n",
      "1954 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000105]\n",
      "1955 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000100]\n",
      "1956 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000151]\n",
      "1957 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000314]\n",
      "1958 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000150]\n",
      "1959 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000121]\n",
      "1960 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000160]\n",
      "1961 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000105]\n",
      "1962 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000359]\n",
      "1963 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000396]\n",
      "1964 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000667]\n",
      "1965 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001117]\n",
      "1966 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000642]\n",
      "1967 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000387]\n",
      "1968 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000987]\n",
      "1969 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001353]\n",
      "1970 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000379]\n",
      "1971 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000195]\n",
      "1972 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000157]\n",
      "1973 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000145]\n",
      "1974 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000084]\n",
      "1975 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000141]\n",
      "1976 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000052]\n",
      "1977 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000169]\n",
      "1978 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000227]\n",
      "1979 [D loss: 0.000089, acc.: 100.00%] [G loss: 0.001106]\n",
      "1980 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000446]\n",
      "1981 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000097]\n",
      "1982 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000159]\n",
      "1983 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000233]\n",
      "1984 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.000606]\n",
      "1985 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000229]\n",
      "1986 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000505]\n",
      "1987 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000186]\n",
      "1988 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000279]\n",
      "1989 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000228]\n",
      "1990 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000094]\n",
      "1991 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000142]\n",
      "1992 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000308]\n",
      "1993 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000137]\n",
      "1994 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000494]\n",
      "1995 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000217]\n",
      "1996 [D loss: 0.001508, acc.: 100.00%] [G loss: 0.000690]\n",
      "1997 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000155]\n",
      "1998 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000096]\n",
      "1999 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000041]\n",
      "2000 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000060]\n",
      "Generating interpolations...\n",
      "2001 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000024]\n",
      "2002 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000042]\n",
      "2003 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000076]\n",
      "2004 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.000086]\n",
      "2005 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000110]\n",
      "2006 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000233]\n",
      "2007 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000141]\n",
      "2008 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000084]\n",
      "2009 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000135]\n",
      "2010 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000269]\n",
      "2011 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000779]\n",
      "2012 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000359]\n",
      "2013 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000235]\n",
      "2014 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000276]\n",
      "2015 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000439]\n",
      "2016 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000966]\n",
      "2017 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000521]\n",
      "2018 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000188]\n",
      "2019 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000243]\n",
      "2020 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000284]\n",
      "2021 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000592]\n",
      "2022 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000165]\n",
      "2023 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000066]\n",
      "2024 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000051]\n",
      "2025 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000171]\n",
      "2026 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000102]\n",
      "2027 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000025]\n",
      "2028 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000026]\n",
      "2029 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000029]\n",
      "2030 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000044]\n",
      "2031 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000068]\n",
      "2032 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000497]\n",
      "2033 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000195]\n",
      "2034 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000132]\n",
      "2035 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000374]\n",
      "2036 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000777]\n",
      "2037 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001155]\n",
      "2038 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000605]\n",
      "2039 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000193]\n",
      "2040 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000493]\n",
      "2041 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000197]\n",
      "2042 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000507]\n",
      "2043 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000400]\n",
      "2044 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000198]\n",
      "2045 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000114]\n",
      "2046 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000115]\n",
      "2047 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000217]\n",
      "2048 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000124]\n",
      "2049 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000063]\n",
      "2050 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000360]\n",
      "2051 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000183]\n",
      "2052 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000188]\n",
      "2053 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000730]\n",
      "2054 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000358]\n",
      "2056 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000146]\n",
      "2057 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000048]\n",
      "2058 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000034]\n",
      "2059 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000096]\n",
      "2060 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000188]\n",
      "2061 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000065]\n",
      "2062 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000088]\n",
      "2063 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000293]\n",
      "2064 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000187]\n",
      "2065 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000139]\n",
      "2066 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000132]\n",
      "2067 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000226]\n",
      "2068 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000086]\n",
      "2069 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000146]\n",
      "2070 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000331]\n",
      "2071 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000078]\n",
      "2072 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000197]\n",
      "2073 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000403]\n",
      "2074 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000087]\n",
      "2075 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000055]\n",
      "2076 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000038]\n",
      "2077 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000110]\n",
      "2078 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000075]\n",
      "2079 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000128]\n",
      "2080 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000088]\n",
      "2081 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000168]\n",
      "2082 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000102]\n",
      "2083 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000073]\n",
      "2084 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000396]\n",
      "2085 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000077]\n",
      "2086 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000104]\n",
      "2087 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000064]\n",
      "2088 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000058]\n",
      "2089 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000210]\n",
      "2090 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000214]\n",
      "2091 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000345]\n",
      "2092 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000087]\n",
      "2093 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000128]\n",
      "2094 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000162]\n",
      "2095 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000217]\n",
      "2096 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000119]\n",
      "2097 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.000723]\n",
      "2098 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.001018]\n",
      "2099 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000609]\n",
      "2100 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000176]\n",
      "Generating interpolations...\n",
      "2101 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000503]\n",
      "2102 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000308]\n",
      "2103 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000211]\n",
      "2104 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000154]\n",
      "2105 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000049]\n",
      "2106 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000118]\n",
      "2107 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000098]\n",
      "2108 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000162]\n",
      "2109 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000085]\n",
      "2110 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000096]\n",
      "2111 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000198]\n",
      "2112 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000429]\n",
      "2113 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000139]\n",
      "2114 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000192]\n",
      "2115 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000728]\n",
      "2116 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000289]\n",
      "2117 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000518]\n",
      "2118 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000154]\n",
      "2119 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000595]\n",
      "2120 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000113]\n",
      "2121 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000263]\n",
      "2122 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000197]\n",
      "2123 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000145]\n",
      "2124 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000204]\n",
      "2125 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000407]\n",
      "2126 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000126]\n",
      "2127 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000077]\n",
      "2128 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000036]\n",
      "2129 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000071]\n",
      "2130 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000101]\n",
      "2131 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000047]\n",
      "2132 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000081]\n",
      "2133 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000191]\n",
      "2134 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000333]\n",
      "2135 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000267]\n",
      "2136 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000203]\n",
      "2137 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000304]\n",
      "2138 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000129]\n",
      "2139 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000275]\n",
      "2140 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000286]\n",
      "2141 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000523]\n",
      "2142 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000566]\n",
      "2143 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001983]\n",
      "2144 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000553]\n",
      "2145 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000603]\n",
      "2146 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000292]\n",
      "2147 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000357]\n",
      "2148 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000261]\n",
      "2149 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000142]\n",
      "2150 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000177]\n",
      "2151 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000245]\n",
      "2152 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000239]\n",
      "2153 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000204]\n",
      "2154 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000050]\n",
      "2155 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000315]\n",
      "2156 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000283]\n",
      "2157 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000318]\n",
      "2158 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000120]\n",
      "2159 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000088]\n",
      "2160 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000130]\n",
      "2161 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000117]\n",
      "2162 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000179]\n",
      "2163 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000203]\n",
      "2164 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000296]\n",
      "2165 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000287]\n",
      "2166 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000417]\n",
      "2167 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000248]\n",
      "2168 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000305]\n",
      "2169 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000297]\n",
      "2170 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000333]\n",
      "2171 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000676]\n",
      "2172 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000502]\n",
      "2173 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000684]\n",
      "2174 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000231]\n",
      "2175 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000125]\n",
      "2176 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000192]\n",
      "2177 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000383]\n",
      "2178 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000352]\n",
      "2179 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000264]\n",
      "2180 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000257]\n",
      "2181 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000764]\n",
      "2182 [D loss: 0.000157, acc.: 100.00%] [G loss: 0.003218]\n",
      "2183 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000536]\n",
      "2184 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000129]\n",
      "2185 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000058]\n",
      "2186 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000050]\n",
      "2187 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000042]\n",
      "2188 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000053]\n",
      "2189 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000058]\n",
      "2190 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000184]\n",
      "2191 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000259]\n",
      "2192 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000630]\n",
      "2193 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000391]\n",
      "2194 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000260]\n",
      "2195 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000174]\n",
      "2197 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000118]\n",
      "2198 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000156]\n",
      "2199 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000426]\n",
      "2200 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000232]\n",
      "Generating interpolations...\n",
      "2201 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000207]\n",
      "2202 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000151]\n",
      "2203 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000281]\n",
      "2204 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000217]\n",
      "2205 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000086]\n",
      "2206 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000102]\n",
      "2207 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000182]\n",
      "2208 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000140]\n",
      "2209 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000440]\n",
      "2210 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000543]\n",
      "2211 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000288]\n",
      "2212 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000869]\n",
      "2213 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001010]\n",
      "2214 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000268]\n",
      "2215 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000293]\n",
      "2216 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000318]\n",
      "2217 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000103]\n",
      "2218 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000132]\n",
      "2219 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000079]\n",
      "2220 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000178]\n",
      "2221 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000156]\n",
      "2222 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000231]\n",
      "2223 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000136]\n",
      "2224 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000132]\n",
      "2225 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000062]\n",
      "2226 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000067]\n",
      "2227 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000056]\n",
      "2228 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000080]\n",
      "2229 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000157]\n",
      "2230 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000196]\n",
      "2231 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000276]\n",
      "2232 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000224]\n",
      "2233 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000128]\n",
      "2234 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000112]\n",
      "2235 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000502]\n",
      "2236 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000450]\n",
      "2237 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000231]\n",
      "2238 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000241]\n",
      "2239 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000313]\n",
      "2240 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000117]\n",
      "2241 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000097]\n",
      "2242 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000180]\n",
      "2243 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000103]\n",
      "2244 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000124]\n",
      "2245 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000052]\n",
      "2246 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000113]\n",
      "2247 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000184]\n",
      "2248 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000146]\n",
      "2249 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000366]\n",
      "2250 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000263]\n",
      "2251 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.001134]\n",
      "2252 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000475]\n",
      "2253 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.001154]\n",
      "2254 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000887]\n",
      "2255 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000180]\n",
      "2256 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000167]\n",
      "2257 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000100]\n",
      "2258 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000105]\n",
      "2259 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000234]\n",
      "2260 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000333]\n",
      "2261 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000170]\n",
      "2262 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000148]\n",
      "2263 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000142]\n",
      "2264 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000296]\n",
      "2265 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000096]\n",
      "2266 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000182]\n",
      "2267 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000112]\n",
      "2268 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000183]\n",
      "2269 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000232]\n",
      "2270 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000237]\n",
      "2271 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000098]\n",
      "2272 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000168]\n",
      "2273 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000120]\n",
      "2274 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000262]\n",
      "2275 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000229]\n",
      "2276 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000103]\n",
      "2277 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000188]\n",
      "2278 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000140]\n",
      "2279 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000087]\n",
      "2280 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000598]\n",
      "2281 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000360]\n",
      "2282 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000170]\n",
      "2283 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000255]\n",
      "2284 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000164]\n",
      "2285 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000146]\n",
      "2286 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000112]\n",
      "2287 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000072]\n",
      "2288 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000118]\n",
      "2289 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000231]\n",
      "2290 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000100]\n",
      "2291 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000078]\n",
      "2292 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000256]\n",
      "2293 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000169]\n",
      "2294 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000238]\n",
      "2295 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000396]\n",
      "2296 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000721]\n",
      "2297 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000195]\n",
      "2298 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000274]\n",
      "2299 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000097]\n",
      "2300 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000096]\n",
      "Generating interpolations...\n",
      "2301 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000133]\n",
      "2302 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000147]\n",
      "2303 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000274]\n",
      "2304 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000096]\n",
      "2305 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000383]\n",
      "2306 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000275]\n",
      "2307 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000225]\n",
      "2308 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000103]\n",
      "2309 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000365]\n",
      "2310 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000538]\n",
      "2311 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000948]\n",
      "2312 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000761]\n",
      "2313 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000554]\n",
      "2314 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000583]\n",
      "2315 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.001203]\n",
      "2316 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000837]\n",
      "2317 [D loss: 0.000001, acc.: 100.00%] [G loss: 0.000473]\n",
      "2318 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000097]\n",
      "2319 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000351]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d112f721c0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-3-8c91a9343846>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        iterations=5000,\n",
    "        batch_size=32,\n",
    "        # save_interval=1000,\n",
    "        save_interval=100, ### epoch100generator\n",
    "        model_interval=200,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
